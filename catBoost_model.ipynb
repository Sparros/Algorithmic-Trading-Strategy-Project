{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab70e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from stock_features import prepare_data_for_ml, create_target_variable\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfb92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for your data pipeline\n",
    "tickers_list = ['PG', 'KO', 'PEP', 'WMT', 'COST', '^GSPC']\n",
    "start_date_str = '1986-01-01'\n",
    "end_date_str = '2023-01-01'\n",
    "output_filename = \"consumer_stocks_final_engineered.csv\"\n",
    "\n",
    "# Make the single function call to run the entire pipeline\n",
    "final_engineered_df = prepare_data_for_ml(\n",
    "    tickers=tickers_list,\n",
    "    start_date=start_date_str,\n",
    "    end_date=end_date_str,\n",
    "    output_engineered_csv=output_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de7c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is ready to be used with the best performing target\n",
    "target_ticker = 'WMT'\n",
    "data_target = create_target_variable(final_engineered_df.copy(), target_ticker, window=5, threshold=0.01)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "target_col_name = f'{target_ticker}_Target'\n",
    "target_return_col_name = [col for col in data_target.columns if col.startswith(f'{target_ticker}_target_return_')][0]\n",
    "columns_to_drop = [target_col_name, target_return_col_name, f'Open_{target_ticker}', f'High_{target_ticker}', f'Low_{target_ticker}', f'Close_{target_ticker}']\n",
    "X = data_target.drop(columns=columns_to_drop)\n",
    "y = data_target[target_col_name]\n",
    "\n",
    "X_train = X.loc[:'2021-01-01'].copy()\n",
    "y_train = y.loc[:'2021-01-01'].copy()\n",
    "X_test = X.loc['2021-01-01':].copy()\n",
    "y_test = y.loc['2021-01-01':].copy()\n",
    "\n",
    "# C. Handle Class Imbalance with CatBoost's built-in feature\n",
    "# CatBoost handles class imbalance automatically with 'auto_class_weights'\n",
    "# No need to manually calculate neg_to_pos_ratio here\n",
    "print(f\"\\n--- Starting Refined CatBoost Grid Search ---\")\n",
    "\n",
    "# Define the model with CatBoost's class imbalance parameter\n",
    "catboost_model = CatBoostClassifier(\n",
    "    random_state=42,\n",
    "    verbose=0, # Set to a higher number to see training output\n",
    "    auto_class_weights='Balanced', # CatBoost's way of handling imbalance\n",
    ")\n",
    "\n",
    "# Define a more refined grid of parameters centered around your best results\n",
    "# CatBoost has different hyperparameter names than XGBoost\n",
    "param_grid = {\n",
    "    'iterations': [150, 200, 250],           # Equivalent to n_estimators\n",
    "    'learning_rate': [0.05, 0.1, 0.2],       # Same name, different best values\n",
    "    'depth': [3, 5, 7],                     # Equivalent to max_depth\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=catboost_model, # <-- CHANGE MODEL HERE\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "print(\"\\n--- Tuned CatBoost Model Evaluation on Test Data ---\")\n",
    "print(classification_report(y_test, y_pred_tuned))\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

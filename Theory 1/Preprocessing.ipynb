{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1e170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b9dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Gilt Yields Data (df_gilts) ---\n",
      "            Gilt_Short_Yield  Gilt_Medium_Yield  Gilt_Long_Yield  \\\n",
      "Month                                                              \n",
      "1998-04-30              5.91               5.70             5.71   \n",
      "1998-05-31              5.82               5.57             5.55   \n",
      "1998-06-30              6.17               5.64             5.43   \n",
      "1998-07-31              6.06               5.57             5.38   \n",
      "1998-08-31              5.52               5.19             5.11   \n",
      "\n",
      "            Gilt_Ultra-Long_Yield  \n",
      "Month                              \n",
      "1998-04-30                    NaN  \n",
      "1998-05-31                    NaN  \n",
      "1998-06-30                    NaN  \n",
      "1998-07-31                    NaN  \n",
      "1998-08-31                    NaN  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 328 entries, 1998-04-30 to 2025-07-31\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Gilt_Short_Yield       328 non-null    float64\n",
      " 1   Gilt_Medium_Yield      328 non-null    float64\n",
      " 2   Gilt_Long_Yield        328 non-null    float64\n",
      " 3   Gilt_Ultra-Long_Yield  242 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 12.8 KB\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epoch_bpjmdqk\\AppData\\Local\\Temp\\ipykernel_11196\\4174078042.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mask = df_gilts[yield_cols].applymap(is_float_or_nan).all(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# --- Section 1: GILT MARKET (Gilt Yields) Data Processing ---\n",
    "\n",
    "gilt_filename = r'data\\20250803 - Historical Average Daily Conventional Gilt Yields.csv'\n",
    "\n",
    "try:\n",
    "    # Read the CSV, skipping the first two rows (metadata/header info)\n",
    "    df_gilts = pd.read_csv(\n",
    "        gilt_filename,\n",
    "        skiprows=2\n",
    "    )\n",
    "\n",
    "    # Drop any rows that are entirely empty (e.g., if there were extra blank lines)\n",
    "    df_gilts = df_gilts.dropna(how='all')\n",
    "\n",
    "    # Rename columns for clarity\n",
    "    df_gilts = df_gilts.rename(columns={\n",
    "        df_gilts.columns[0]: 'Month',\n",
    "        df_gilts.columns[1]: 'Short',\n",
    "        df_gilts.columns[2]: 'Medium',\n",
    "        df_gilts.columns[3]: 'Long',\n",
    "        df_gilts.columns[4]: 'Ultra-Long'\n",
    "    })\n",
    "\n",
    "    # Strip any leading/trailing whitespace (including non-breaking spaces like '\\xa0') from the 'Month' column\n",
    "    df_gilts['Month'] = df_gilts['Month'].astype(str).str.strip()\n",
    "\n",
    "    # Convert the 'Month' column to datetime objects.\n",
    "    # We add MonthEnd(0) to set the date to the last day of the month for consistency.\n",
    "    df_gilts['Month'] = pd.to_datetime(df_gilts['Month'], format='%b-%Y', errors='coerce') + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    # Add this line to drop rows where Month conversion failed (NaT index) for robustness\n",
    "    df_gilts = df_gilts.dropna(subset=['Month'])\n",
    "\n",
    "    # Set the 'Month' column as the DataFrame index\n",
    "    df_gilts = df_gilts.set_index('Month')\n",
    "\n",
    "    # Clean column names by removing any leading/trailing spaces\n",
    "    df_gilts.columns = df_gilts.columns.str.strip()\n",
    "\n",
    "    # Process the yield columns: remove '%' sign and convert to float\n",
    "    yield_cols = ['Short', 'Medium', 'Long', 'Ultra-Long']\n",
    "\n",
    "    # Remove rows where any yield column contains non-numeric values (excluding NaN)\n",
    "    # First, process the values by removing '%'\n",
    "    for col in yield_cols:\n",
    "        if col in df_gilts.columns:\n",
    "            # Convert to string first to handle potential NaNs or non-string types, then replace\n",
    "            df_gilts[col] = df_gilts[col].astype(str).str.replace('%', '', regex=False)\n",
    "\n",
    "    # Keep only rows where all yield columns are either numeric or NaN after '%' removal\n",
    "    # Define the helper function (if not already defined elsewhere)\n",
    "    def is_float_or_nan(x):\n",
    "        try:\n",
    "            float(x)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return pd.isna(x) or (isinstance(x, str) and x.strip() == '')\n",
    "\n",
    "    # Apply the mask. Suppress FutureWarning for applymap, or use .map() if you prefer.\n",
    "    # You might consider .map() for Series if processing column by column or if performance is critical.\n",
    "    # For a DataFrame with multiple columns, applymap or apply with lambda and Series.map is typical.\n",
    "    mask = df_gilts[yield_cols].applymap(is_float_or_nan).all(axis=1)\n",
    "    df_gilts = df_gilts[mask]\n",
    "\n",
    "    # Now convert columns to float\n",
    "    for col in yield_cols:\n",
    "        if col in df_gilts.columns:\n",
    "            df_gilts[col] = df_gilts[col].astype(float)\n",
    "        # Rename columns for clarity, e.g., 'Short' becomes 'Gilt_Short_Yield'\n",
    "        df_gilts = df_gilts.rename(columns={col: f'Gilt_{col}_Yield'})\n",
    "\n",
    "    print(\"--- Gilt Yields Data (df_gilts) ---\")\n",
    "    print(df_gilts.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df_gilts.info()\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Gilt Yields file '{gilt_filename}' not found. Skipping Gilt Yields processing.\")\n",
    "    df_gilts = pd.DataFrame() # Create an empty DataFrame to prevent errors later\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during Gilt Yields processing: {e}\")\n",
    "    df_gilts = pd.DataFrame() # Create an empty DataFrame on other errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da88089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Bank Rate file 'Hypoth\\data\\Bank Rate history and data  Bank of England Database.csv' not found. Skipping Bank Rate processing.\n"
     ]
    }
   ],
   "source": [
    "# --- Section 2: Bank Rate Data Processing ---\n",
    "\n",
    "bank_rate_filename = r'Hypoth\\data\\Bank Rate history and data  Bank of England Database.csv'\n",
    "\n",
    "try:\n",
    "    df_bank_rate = pd.read_csv(bank_rate_filename)\n",
    "\n",
    "    # Drop any rows that are entirely empty\n",
    "    df_bank_rate = df_bank_rate.dropna(how='all')\n",
    "\n",
    "    if df_bank_rate.empty:\n",
    "        raise ValueError(\"Bank Rate CSV loaded but is empty. Check the file content.\")\n",
    "\n",
    "    # Convert 'Date Changed' to datetime objects using the specified format\n",
    "    # Use errors='coerce' to turn unparseable dates into NaT\n",
    "    df_bank_rate['Date Changed'] = pd.to_datetime(df_bank_rate['Date Changed'], format='%d %b %y', errors='coerce')\n",
    "\n",
    "    # Drop rows where date conversion failed (i.e., Date Changed is NaT)\n",
    "    df_bank_rate = df_bank_rate.dropna(subset=['Date Changed'])\n",
    "\n",
    "    # Set 'Date Changed' as the index and sort it in ascending order (chronological)\n",
    "    df_bank_rate = df_bank_rate.set_index('Date Changed').sort_index()\n",
    "\n",
    "    # Rename the 'Rate' column for clarity\n",
    "    df_bank_rate = df_bank_rate.rename(columns={'Rate': 'Bank_Rate'})\n",
    "\n",
    "    # Convert the 'Bank_Rate' column to float\n",
    "    df_bank_rate['Bank_Rate'] = df_bank_rate['Bank_Rate'].astype(float)\n",
    "\n",
    "    print(\"--- Bank Rate Data (df_bank_rate) ---\")\n",
    "    print(df_bank_rate.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df_bank_rate.info()\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Bank Rate file '{bank_rate_filename}' not found. Skipping Bank Rate processing.\")\n",
    "    df_bank_rate = pd.DataFrame() # Create an empty DataFrame to prevent errors later\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Bank Rate processing: {e}\")\n",
    "    df_bank_rate = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19206fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SONIA Data (df_sonia) ---\n",
      "            SONIA_Rate\n",
      "Date                  \n",
      "2014-01-02      0.4264\n",
      "2014-01-03      0.4256\n",
      "2014-01-06      0.4304\n",
      "2014-01-07      0.4332\n",
      "2014-01-08      0.4282\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2925 entries, 2014-01-02 to 2025-07-30\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SONIA_Rate  2925 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 45.7 KB\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Section 3: SONIA Data Processing (REVISED BASED ON YOUR LATEST INPUT) ---\n",
    "\n",
    "sonia_filename = r'data\\SONIA.csv'\n",
    "\n",
    "try:\n",
    "    # Read the CSV. Explicitly specify the separator as comma.\n",
    "    # The header is on the first line, so no skiprows is needed.\n",
    "    df_sonia = pd.read_csv(sonia_filename, sep=',')\n",
    "\n",
    "    # Drop any rows that are entirely empty\n",
    "    df_sonia = df_sonia.dropna(how='all')\n",
    "\n",
    "    # The actual SONIA rate column has a very long, messy name.\n",
    "    # It should be the second column (index 1) after the 'Date' column.\n",
    "    if len(df_sonia.columns) >= 2:\n",
    "        long_sonia_col_name = df_sonia.columns[1] # Get the second column name\n",
    "    else:\n",
    "        raise ValueError(\"SONIA CSV does not have enough columns after parsing with comma delimiter. \"\n",
    "                         \"Check if the file is truly comma-separated.\")\n",
    "\n",
    "    # Rename the columns for clarity\n",
    "    df_sonia = df_sonia.rename(columns={\n",
    "        df_sonia.columns[0]: 'Date', # First column is 'Date'\n",
    "        long_sonia_col_name: 'SONIA_Rate' # Rename the long column\n",
    "    })\n",
    "\n",
    "    # Convert 'Date' to datetime objects using the specified format\n",
    "    df_sonia['Date'] = pd.to_datetime(df_sonia['Date'], format='%d %b %y', errors='coerce')\n",
    "\n",
    "    # Drop rows where date conversion failed (NaT)\n",
    "    df_sonia = df_sonia.dropna(subset=['Date'])\n",
    "\n",
    "    # Set 'Date' as the index and sort it in ascending order (chronological)\n",
    "    df_sonia = df_sonia.set_index('Date').sort_index()\n",
    "\n",
    "    # Convert the 'SONIA_Rate' column to float\n",
    "    df_sonia['SONIA_Rate'] = df_sonia['SONIA_Rate'].astype(float)\n",
    "\n",
    "    print(\"--- SONIA Data (df_sonia) ---\")\n",
    "    print(df_sonia.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df_sonia.info()\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: SONIA file '{sonia_filename}' not found. Skipping SONIA processing.\")\n",
    "    df_sonia = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during SONIA processing: {e}\")\n",
    "    df_sonia = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7b5e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stock Data (df_stocks) ---\n",
      "                  ^FTSE      LLOY.L      BARC.L        AV.L       PSN.L  \\\n",
      "Date                                                                      \n",
      "2000-01-03          NaN  498.020142  408.222687  972.562134  237.982162   \n",
      "2000-01-04  6665.899902  466.833557  382.565521  908.244202  237.982162   \n",
      "2000-01-05  6535.899902  466.190460  373.402405  880.958130  234.024033   \n",
      "2000-01-06  6447.200195  450.757965  359.428284  873.161926  234.024033   \n",
      "2000-01-07  6504.799805  435.003906  351.410492  892.652161  235.013565   \n",
      "\n",
      "                LAND.L  \n",
      "Date                    \n",
      "2000-01-03  650.739258  \n",
      "2000-01-04  631.986145  \n",
      "2000-01-05  646.519775  \n",
      "2000-01-06  646.519775  \n",
      "2000-01-07  649.333130  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6364 entries, 2000-01-03 to 2024-12-30\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ^FTSE   6313 non-null   float64\n",
      " 1   LLOY.L  6364 non-null   float64\n",
      " 2   BARC.L  6364 non-null   float64\n",
      " 3   AV.L    6364 non-null   float64\n",
      " 4   PSN.L   6364 non-null   float64\n",
      " 5   LAND.L  6364 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 348.0 KB\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Section 4: Stock Data Processing ---\n",
    "\n",
    "stock_filename = r'data\\uk_stock_data.csv'\n",
    "\n",
    "try:\n",
    "    df_stocks = pd.read_csv(stock_filename)\n",
    "\n",
    "    # Drop any rows that are entirely empty\n",
    "    df_stocks = df_stocks.dropna(how='all')\n",
    "\n",
    "    # Convert 'Date' to datetime objects. Pandas is usually good at inferring YYYY-MM-DD.\n",
    "    df_stocks['Date'] = pd.to_datetime(df_stocks['Date'], errors='coerce')\n",
    "\n",
    "    # Drop rows with failed date parsing\n",
    "    df_stocks = df_stocks.dropna(subset=['Date'])\n",
    "\n",
    "    # Set 'Date' as the index and sort it\n",
    "    df_stocks = df_stocks.set_index('Date').sort_index()\n",
    "\n",
    "    # Convert all stock price columns to numeric, coercing any errors (like non-numeric strings) to NaN\n",
    "    # We apply this to all columns that are not the index.\n",
    "    for col in df_stocks.columns:\n",
    "        df_stocks[col] = pd.to_numeric(df_stocks[col], errors='coerce')\n",
    "\n",
    "    print(\"--- Stock Data (df_stocks) ---\")\n",
    "    print(df_stocks.head())\n",
    "    print(\"\\nDataFrame Info:\")\n",
    "    df_stocks.info()\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Stock data file '{stock_filename}' not found. Skipping Stock processing.\")\n",
    "    df_stocks = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during Stock processing: {e}\")\n",
    "    df_stocks = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c807f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ^FTSE  LLOY.L  BARC.L  AV.L  PSN.L  LAND.L  Gilt_Short_Yield  \\\n",
      "1998-04-30    NaN     NaN     NaN   NaN    NaN     NaN              5.91   \n",
      "1998-05-01    NaN     NaN     NaN   NaN    NaN     NaN              5.91   \n",
      "1998-05-02    NaN     NaN     NaN   NaN    NaN     NaN              5.91   \n",
      "1998-05-03    NaN     NaN     NaN   NaN    NaN     NaN              5.91   \n",
      "1998-05-04    NaN     NaN     NaN   NaN    NaN     NaN              5.91   \n",
      "\n",
      "            Gilt_Medium_Yield  Gilt_Long_Yield  Gilt_Ultra-Long_Yield  \\\n",
      "1998-04-30                5.7             5.71                    NaN   \n",
      "1998-05-01                5.7             5.71                    NaN   \n",
      "1998-05-02                5.7             5.71                    NaN   \n",
      "1998-05-03                5.7             5.71                    NaN   \n",
      "1998-05-04                5.7             5.71                    NaN   \n",
      "\n",
      "            SONIA_Rate  \n",
      "1998-04-30         NaN  \n",
      "1998-05-01         NaN  \n",
      "1998-05-02         NaN  \n",
      "1998-05-03         NaN  \n",
      "1998-05-04         NaN  \n",
      "\n",
      "Merged DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9955 entries, 1998-04-30 to 2025-07-31\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   ^FTSE                  6313 non-null   float64\n",
      " 1   LLOY.L                 6364 non-null   float64\n",
      " 2   BARC.L                 6364 non-null   float64\n",
      " 3   AV.L                   6364 non-null   float64\n",
      " 4   PSN.L                  6364 non-null   float64\n",
      " 5   LAND.L                 6364 non-null   float64\n",
      " 6   Gilt_Short_Yield       9955 non-null   float64\n",
      " 7   Gilt_Medium_Yield      9955 non-null   float64\n",
      " 8   Gilt_Long_Yield        9955 non-null   float64\n",
      " 9   Gilt_Ultra-Long_Yield  7337 non-null   float64\n",
      " 10  SONIA_Rate             2925 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 933.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Merge all dataframes on their datetime index (outer join to keep all available data)\n",
    "# Start by merging df_stocks and df_gilts (monthly), then merge df_sonia (daily)\n",
    "\n",
    "# First, resample df_gilts to daily frequency to match others (forward fill monthly values)\n",
    "df_gilts_daily = df_gilts.resample('D').ffill()\n",
    "\n",
    "# Merge stocks and gilts\n",
    "df_merged = df_stocks.join(df_gilts_daily, how='outer')\n",
    "\n",
    "# Merge SONIA\n",
    "df_merged = df_merged.join(df_sonia, how='outer')\n",
    "\n",
    "# Merge Bank Rate \n",
    "df_merged = df_merged.join(df_bank_rate, how='outer')\n",
    "\n",
    "print(df_merged.head())\n",
    "print(\"\\nMerged DataFrame Info:\")\n",
    "df_merged.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f471a31",
   "metadata": {},
   "source": [
    "### Data Pipeline — Sector Builds with Macro As-Of Merge, Rolling Transforms, and Manifests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca51a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Transform utilities (assumed to exist in your repo)\n",
    "from src.transforms.macro_asof import AsOfMacroMerger\n",
    "from src.transforms.rolling import RollingImputer, RollingStandardizer, Winsorizer\n",
    "from src.transforms.pruning import drop_sparse_columns\n",
    "from src.transforms.manifests import ManifestWriter, hash_df_map\n",
    "\n",
    "# QA helpers (defined below in src/qa/)\n",
    "from src.qa.validators import validate_df, assert_no_future, assert_monotonic\n",
    "\n",
    "PUBLISH_LAGS = {\n",
    "    \"CPIAUCSL\": 2, \"DFF\": 1, \"DGS10\": 1,\n",
    "    \"UNRATE\": 2, \"GDPC1\": 5, \"RSAFS\": 3, \"PAYEMS\": 2\n",
    "}\n",
    "\n",
    "from src.stock_features import (\n",
    "    build_stock_features_orchestrator,\n",
    "    build_sector_base_features,\n",
    "    make_target_view\n",
    ")\n",
    "\n",
    "from src.macro_features import (\n",
    "    macro_data_orchestrator,\n",
    "    normalize_date_index,\n",
    "    prepare_macro_for_daily_merge,\n",
    "    merge_stocks_and_macros,\n",
    "    build_macro_state_features,\n",
    "    apply_publish_lags\n",
    ")\n",
    "\n",
    "# -------- Config --------\n",
    "base_output_dir = r\"C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\"\n",
    "macro_folder    = r\"C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\raw\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00248952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Sector definitions --------\n",
    "SECTORS = {\n",
    "    \"staples\": {\n",
    "        \"tickers\": [\"WMT\",\"PG\",\"KO\",\"PEP\",\"COST\",\"CL\",\"CLX\",\"KMB\",\"GIS\",\"MDLZ\",\"KR\",\"TGT\",\"XLP\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLP\",\n",
    "    },\n",
    "    \"discretionary\": {\n",
    "        \"tickers\": [\"AMZN\",\"HD\",\"MCD\",\"NKE\",\"SBUX\",\"TJX\",\"LOW\",\"BKNG\",\"ROST\",\"MAR\",\"XLY\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLY\",\n",
    "    },\n",
    "    \"healthcare\": {\n",
    "        \"tickers\": [\"UNH\",\"LLY\",\"JNJ\",\"ABBV\",\"MRK\",\"TMO\",\"ABT\",\"PFE\",\"MDT\",\"ISRG\",\"CVS\",\"HUM\",\"XLV\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLV\",\n",
    "    },\n",
    "    \"technology\": {\n",
    "        \"tickers\": [\"AAPL\",\"MSFT\",\"NVDA\",\"AVGO\",\"ADBE\",\"CRM\",\"AMD\",\"INTC\",\"CSCO\",\"QCOM\",\"ORCL\",\"TXN\",\"XLK\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLK\",\n",
    "    },\n",
    "    \"financials\": {\n",
    "        \"tickers\": [\"JPM\",\"BAC\",\"WFC\",\"MS\",\"GS\",\"C\",\"BLK\",\"PGR\",\"AXP\",\"USB\",\"SCHW\",\"CB\",\"XLF\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLF\",\n",
    "    },\n",
    "    \"energy\": {\n",
    "        \"tickers\": [\"XOM\",\"CVX\",\"COP\",\"EOG\",\"SLB\",\"OXY\",\"PSX\",\"MPC\",\"VLO\",\"HAL\",\"KMI\",\"XLE\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLE\",\n",
    "    },\n",
    "    \"industrials\": {\n",
    "        \"tickers\": [\"CAT\",\"BA\",\"HON\",\"GE\",\"UPS\",\"UNP\",\"DE\",\"RTX\",\"LMT\",\"ETN\",\"EMR\",\"MMM\",\"XLI\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLI\",\n",
    "    },\n",
    "    \"utilities\": {\n",
    "        \"tickers\": [\"NEE\",\"SO\",\"DUK\",\"AEP\",\"EXC\",\"SRE\",\"XEL\",\"D\",\"PEG\",\"ED\",\"XLU\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLU\",\n",
    "    },\n",
    "    \"materials\": {\n",
    "        \"tickers\": [\"LIN\",\"APD\",\"ECL\",\"NEM\",\"FCX\",\"NUE\",\"SHW\",\"ALB\",\"MLM\",\"VMC\",\"XLB\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLB\",\n",
    "    },\n",
    "    \"communication_services\": {\n",
    "        \"tickers\": [\"META\",\"GOOGL\",\"GOOG\",\"NFLX\",\"CMCSA\",\"DIS\",\"T\",\"VZ\",\"XLC\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLC\",\n",
    "    },\n",
    "    \"real_estate\": {\n",
    "        \"tickers\": [\"AMT\",\"PLD\",\"EQIX\",\"PSA\",\"SPG\",\"CCI\",\"O\",\"WELL\",\"XLRE\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLRE\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8a2868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing macro data from CSV.\n",
      "[validate] macro_daily: replaced 61621 ±inf with NaN\n",
      "[validate] macro_daily+state: replaced 257656 ±inf with NaN\n",
      "[validate] macro_daily+state: dropping all-NaN columns: ['regime_hmm', 'yc_level_10y_chg_5_surprise_proxy_z', 'carry_10y_ff_chg_5_surprise_proxy_z', 'regime_hmm_surprise_proxy_z']\n"
     ]
    }
   ],
   "source": [
    "# (optional) date range\n",
    "start_date_str = None  \n",
    "end_date_str   = None  \n",
    "\n",
    "FRED_series_ids = {\n",
    "    'CPI': 'CPIAUCSL',\n",
    "    'FEDERAL_FUNDS_RATE': 'DFF',\n",
    "    'TREASURY_YIELD': 'DGS10',\n",
    "    'UNEMPLOYMENT': 'UNRATE',\n",
    "    'REAL_GDP': 'GDPC1',\n",
    "    'RETAIL_SALES': 'RSAFS',\n",
    "    'PAYEMS': 'PAYEMS'\n",
    "}\n",
    "\n",
    "macro_funcs = {'CPI','FEDERAL_FUNDS_RATE','TREASURY_YIELD','UNEMPLOYMENT','REAL_GDP','RETAIL_SALES','PAYEMS'}\n",
    "\n",
    "# ---- Load / build macro data ----\n",
    "try:\n",
    "    macro_df = pd.read_csv(os.path.join(macro_folder, \"macros.csv\"),\n",
    "                           index_col=\"date\", parse_dates=[\"date\"])\n",
    "    macro_df.index = macro_df.index.tz_localize(None).normalize()\n",
    "    print(\"Loaded existing macro data from CSV.\")\n",
    "except FileNotFoundError:\n",
    "    macro_df = macro_data_orchestrator(macro_funcs_to_fetch=macro_funcs,\n",
    "                                       fred_series_ids_dict=FRED_series_ids,\n",
    "                                       start_date=start_date_str,\n",
    "                                       save_path=macro_folder)\n",
    "\n",
    "# keep a clean DatetimeIndex\n",
    "macro_df = normalize_date_index(macro_df)\n",
    "\n",
    "# prep for asof (returns a 'Date' column on business-day grid)\n",
    "macro_daily = prepare_macro_for_daily_merge(macro_df)\n",
    "\n",
    "# Apply series-specific publish lags to mimic availability (macro-only)\n",
    "macro_daily = apply_publish_lags(macro_daily, PUBLISH_LAGS, date_col=\"Date\")\n",
    "\n",
    "# Validate macro\n",
    "macro_daily = validate_df(macro_daily.set_index(\"Date\"), \"macro_daily\")\n",
    "\n",
    "# Enrich features; set publish_lags=None to avoid double-lagging\n",
    "macro_daily = build_macro_state_features(macro_daily, publish_lags=None, pca_cols=None, use_hmm=False)\n",
    "macro_daily = validate_df(macro_daily, \"macro_daily+state\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building sector BASE (target-agnostic) ---\n",
      "Fetching data for 14 tickers...\n",
      "Date range: All available history to Current date\n",
      "Fetching full history for WMT...\n",
      "Fetching full history for PG...\n",
      "Fetching full history for KO...\n",
      "Fetching full history for PEP...\n",
      "Fetching full history for COST...\n",
      "Fetching full history for CL...\n",
      "Fetching full history for CLX...\n",
      "Fetching full history for KMB...\n",
      "Fetching full history for GIS...\n",
      "Fetching full history for MDLZ...\n",
      "Fetching full history for KR...\n",
      "Fetching full history for TGT...\n",
      "Fetching full history for XLP...\n",
      "Fetching full history for ^GSPC...\n",
      "\n",
      "Final merged DataFrame has 6092 common entries.\n",
      "Discovered prefixes: ['CL', 'CLX', 'COST', 'GIS', 'KMB', 'KO', 'KR', 'MDLZ', 'PEP', 'PG', 'TGT', 'WMT', 'XLP', '^GSPC']\n",
      "Dropped 49 rows (base pruning @ 90%).\n",
      "Saved BASE → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__BASE.parquet\n",
      "[validate] staples::BASE: replaced 3467 ±inf with NaN\n",
      "\n",
      "--- staples :: target=WMT ---\n",
      "[validate] staples::WMT::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::WMT::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::WMT: trimmed first 60 warm-up rows\n",
      "Saved staples::WMT → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__WMT.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=PG ---\n",
      "[validate] staples::PG::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::PG::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::PG: trimmed first 60 warm-up rows\n",
      "Saved staples::PG → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__PG.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=KO ---\n",
      "[validate] staples::KO::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::KO::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::KO: trimmed first 60 warm-up rows\n",
      "Saved staples::KO → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__KO.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=PEP ---\n",
      "[validate] staples::PEP::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::PEP::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::PEP: trimmed first 60 warm-up rows\n",
      "Saved staples::PEP → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__PEP.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=COST ---\n",
      "[validate] staples::COST::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::COST::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::COST: trimmed first 60 warm-up rows\n",
      "Saved staples::COST → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__COST.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=CL ---\n",
      "[validate] staples::CL::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::CL::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::CL: trimmed first 60 warm-up rows\n",
      "Saved staples::CL → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__CL.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=CLX ---\n",
      "[validate] staples::CLX::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::CLX::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::CLX: trimmed first 60 warm-up rows\n",
      "Saved staples::CLX → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__CLX.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=KMB ---\n",
      "[validate] staples::KMB::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::KMB::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::KMB: trimmed first 60 warm-up rows\n",
      "Saved staples::KMB → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__KMB.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=GIS ---\n",
      "[validate] staples::GIS::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::GIS::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::GIS: trimmed first 60 warm-up rows\n",
      "Saved staples::GIS → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__GIS.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=MDLZ ---\n",
      "[validate] staples::MDLZ::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::MDLZ::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::MDLZ: trimmed first 60 warm-up rows\n",
      "Saved staples::MDLZ → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__MDLZ.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=KR ---\n",
      "[validate] staples::KR::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::KR::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::KR: trimmed first 60 warm-up rows\n",
      "Saved staples::KR → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__KR.csv rows=5,983 cols=1130\n",
      "\n",
      "--- staples :: target=TGT ---\n",
      "[validate] staples::TGT::target_view: replaced 3633 ±inf with NaN\n",
      "[validate] staples::TGT::merged: replaced 14790 ±inf with NaN\n",
      "[finalize] staples::TGT: trimmed first 60 warm-up rows\n",
      "Saved staples::TGT → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\staples__TGT.csv rows=5,983 cols=1130\n",
      "\n",
      "--- Building sector BASE (target-agnostic) ---\n",
      "Fetching data for 12 tickers...\n",
      "Date range: All available history to Current date\n",
      "Fetching full history for AMZN...\n",
      "Fetching full history for HD...\n",
      "Fetching full history for MCD...\n",
      "Fetching full history for NKE...\n",
      "Fetching full history for SBUX...\n",
      "Fetching full history for TJX...\n",
      "Fetching full history for LOW...\n",
      "Fetching full history for BKNG...\n",
      "Fetching full history for ROST...\n",
      "Fetching full history for MAR...\n",
      "Fetching full history for XLY...\n",
      "Fetching full history for ^GSPC...\n",
      "\n",
      "Final merged DataFrame has 6647 common entries.\n",
      "Discovered prefixes: ['AMZN', 'BKNG', 'HD', 'LOW', 'MAR', 'MCD', 'NKE', 'ROST', 'SBUX', 'TJX', 'XLY', '^GSPC']\n",
      "Dropped 49 rows (base pruning @ 90%).\n",
      "Saved BASE → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__BASE.parquet\n",
      "[validate] discretionary::BASE: replaced 2986 ±inf with NaN\n",
      "\n",
      "--- discretionary :: target=AMZN ---\n",
      "[validate] discretionary::AMZN::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::AMZN::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::AMZN: trimmed first 60 warm-up rows\n",
      "Saved discretionary::AMZN → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__AMZN.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=HD ---\n",
      "[validate] discretionary::HD::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::HD::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::HD: trimmed first 60 warm-up rows\n",
      "Saved discretionary::HD → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__HD.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=MCD ---\n",
      "[validate] discretionary::MCD::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::MCD::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::MCD: trimmed first 60 warm-up rows\n",
      "Saved discretionary::MCD → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__MCD.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=NKE ---\n",
      "[validate] discretionary::NKE::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::NKE::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::NKE: trimmed first 60 warm-up rows\n",
      "Saved discretionary::NKE → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__NKE.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=SBUX ---\n",
      "[validate] discretionary::SBUX::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::SBUX::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::SBUX: trimmed first 60 warm-up rows\n",
      "Saved discretionary::SBUX → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__SBUX.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=TJX ---\n",
      "[validate] discretionary::TJX::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::TJX::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::TJX: trimmed first 60 warm-up rows\n",
      "Saved discretionary::TJX → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__TJX.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=LOW ---\n",
      "[validate] discretionary::LOW::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::LOW::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::LOW: trimmed first 60 warm-up rows\n",
      "Saved discretionary::LOW → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__LOW.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=BKNG ---\n",
      "[validate] discretionary::BKNG::target_view: replaced 3153 ±inf with NaN\n",
      "[validate] discretionary::BKNG::merged: replaced 15275 ±inf with NaN\n",
      "[finalize] discretionary::BKNG: trimmed first 60 warm-up rows\n",
      "Saved discretionary::BKNG → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__BKNG.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=ROST ---\n",
      "[validate] discretionary::ROST::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::ROST::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::ROST: trimmed first 60 warm-up rows\n",
      "Saved discretionary::ROST → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__ROST.csv rows=6,538 cols=975\n",
      "\n",
      "--- discretionary :: target=MAR ---\n",
      "[validate] discretionary::MAR::target_view: replaced 3145 ±inf with NaN\n",
      "[validate] discretionary::MAR::merged: replaced 15267 ±inf with NaN\n",
      "[finalize] discretionary::MAR: trimmed first 60 warm-up rows\n",
      "Saved discretionary::MAR → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\discretionary__MAR.csv rows=6,538 cols=975\n",
      "\n",
      "--- Building sector BASE (target-agnostic) ---\n",
      "Fetching data for 14 tickers...\n",
      "Date range: All available history to Current date\n",
      "Fetching full history for UNH...\n",
      "Fetching full history for LLY...\n",
      "Fetching full history for JNJ...\n",
      "Fetching full history for ABBV...\n",
      "Fetching full history for MRK...\n",
      "Fetching full history for TMO...\n",
      "Fetching full history for ABT...\n",
      "Fetching full history for PFE...\n",
      "Fetching full history for MDT...\n",
      "Fetching full history for ISRG...\n",
      "Fetching full history for CVS...\n",
      "Fetching full history for HUM...\n",
      "Fetching full history for XLV...\n",
      "Fetching full history for ^GSPC...\n",
      "\n",
      "Final merged DataFrame has 3186 common entries.\n",
      "Discovered prefixes: ['ABBV', 'ABT', 'CVS', 'HUM', 'ISRG', 'JNJ', 'LLY', 'MDT', 'MRK', 'PFE', 'TMO', 'UNH', 'XLV', '^GSPC']\n",
      "Dropped 49 rows (base pruning @ 90%).\n",
      "Saved BASE → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\healthcare__BASE.parquet\n",
      "[validate] healthcare::BASE: replaced 3468 ±inf with NaN\n",
      "\n",
      "--- healthcare :: target=UNH ---\n",
      "[validate] healthcare::UNH::target_view: replaced 3634 ±inf with NaN\n",
      "[validate] healthcare::UNH::merged: replaced 9360 ±inf with NaN\n",
      "[finalize] healthcare::UNH: trimmed first 60 warm-up rows\n",
      "Saved healthcare::UNH → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\healthcare__UNH.csv rows=3,077 cols=1130\n",
      "\n",
      "--- healthcare :: target=LLY ---\n",
      "[validate] healthcare::LLY::target_view: replaced 3634 ±inf with NaN\n",
      "[validate] healthcare::LLY::merged: replaced 9360 ±inf with NaN\n",
      "[finalize] healthcare::LLY: trimmed first 60 warm-up rows\n",
      "Saved healthcare::LLY → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\healthcare__LLY.csv rows=3,077 cols=1130\n",
      "\n",
      "--- healthcare :: target=JNJ ---\n",
      "[validate] healthcare::JNJ::target_view: replaced 3634 ±inf with NaN\n",
      "[validate] healthcare::JNJ::merged: replaced 9360 ±inf with NaN\n",
      "[finalize] healthcare::JNJ: trimmed first 60 warm-up rows\n",
      "Saved healthcare::JNJ → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\healthcare__JNJ.csv rows=3,077 cols=1130\n",
      "\n",
      "--- healthcare :: target=ABBV ---\n",
      "[validate] healthcare::ABBV::target_view: replaced 3634 ±inf with NaN\n",
      "[validate] healthcare::ABBV::merged: replaced 9360 ±inf with NaN\n",
      "[finalize] healthcare::ABBV: trimmed first 60 warm-up rows\n",
      "Saved healthcare::ABBV → C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\healthcare__ABBV.csv rows=3,077 cols=1130\n",
      "\n",
      "--- healthcare :: target=MRK ---\n",
      "[validate] healthcare::MRK::target_view: replaced 3634 ±inf with NaN\n",
      "[validate] healthcare::MRK::merged: replaced 9360 ±inf with NaN\n",
      "[finalize] healthcare::MRK: trimmed first 60 warm-up rows\n"
     ]
    }
   ],
   "source": [
    "# ---- Sector loop ----\n",
    "for sector_name, cfg in SECTORS.items():\n",
    "    tickers    = cfg[\"tickers\"]\n",
    "    sector_etf = cfg.get(\"sector_etf\")\n",
    "\n",
    "    # 1) Base features per sector (cacheable)\n",
    "    base_path = os.path.join(base_output_dir, f\"{sector_name}__BASE.parquet\")\n",
    "    if os.path.exists(base_path):\n",
    "        base_df = pd.read_parquet(base_path)\n",
    "        print(f\"[cache] loaded {base_path}\")\n",
    "    else:\n",
    "        base_df = build_sector_base_features(\n",
    "            tickers=tickers,\n",
    "            kalman_lags=[1,5,10],\n",
    "            dropna_frac=0.90,\n",
    "            output_path=base_path\n",
    "        )\n",
    "    base_df = validate_df(base_df, f\"{sector_name}::BASE\")\n",
    "    base_df = drop_sparse_columns(base_df, 0.20)\n",
    "\n",
    "    # 2) Target views + macro merge\n",
    "    equities = [t for t in tickers if not t.startswith(\"^\") and t != sector_etf]\n",
    "    for target in equities:\n",
    "        suppliers = [t for t in equities if t != target]\n",
    "        print(f\"\\n--- {sector_name} :: target={target} ---\")\n",
    "\n",
    "        df_t = make_target_view(\n",
    "            base_df,\n",
    "            target_ticker=target,\n",
    "            supplier_tickers=suppliers,\n",
    "            benchmark_ticker=\"^GSPC\",\n",
    "            sector_etf=sector_etf\n",
    "        )\n",
    "        df_t = validate_df(df_t, f\"{sector_name}::{target}::target_view\")\n",
    "\n",
    "        # As-of safe merge with macro\n",
    "        df_t_for_merge   = df_t.reset_index().rename(columns={df_t.index.name or \"index\": \"Date\"})\n",
    "        macro_for_merge  = macro_daily.reset_index()\n",
    "        merged           = merge_stocks_and_macros(stock_df=df_t_for_merge, macro_df=macro_for_merge, tolerance_days=31)\n",
    "\n",
    "        merged = merged.set_index(\"Date\")\n",
    "        merged = validate_df(merged, f\"{sector_name}::{target}::merged\")\n",
    "        merged = drop_sparse_columns(merged, 0.20)\n",
    "\n",
    "        # ---- Fast QA guards (fail fast) ----\n",
    "        assert_monotonic(merged.index)\n",
    "        assert_no_future(merged.index, macro_daily.index)\n",
    "        if merged.index.duplicated().any():\n",
    "            raise ValueError(f\"[{sector_name}::{target}] Duplicate index rows detected\")\n",
    "\n",
    "        # Warm-up trim (indicators, rolling) and row-level NA filter\n",
    "        if len(merged) > 60:\n",
    "            merged = merged.iloc[60:]\n",
    "            print(f\"[finalize] {sector_name}::{target}: trimmed first 60 warm-up rows\")\n",
    "\n",
    "        min_non_null = int(0.85 * merged.shape[1])\n",
    "        merged = merged.loc[merged.notna().sum(axis=1) >= min_non_null]\n",
    "\n",
    "        # 3) Rolling, no-lookahead transforms\n",
    "        pipe = Pipeline([\n",
    "            # expanding quantile winsorization (shifted) — ~1%/99% tails, needs history\n",
    "            (\"winsor\", Winsorizer(lower_q=0.01, upper_q=0.99, min_periods=200)),\n",
    "            # expanding-mean imputer using only past data\n",
    "            (\"imputer\", RollingImputer(min_periods=20)),\n",
    "            # expanding z-score using only past data (optionally clip to avoid extreme z’s)\n",
    "            (\"scaler\", RollingStandardizer(min_periods=60, clip_sigma=4.0)),\n",
    "        ])\n",
    "        merged_proc = pipe.fit_transform(merged)\n",
    "\n",
    "        # 4) Manifest logging (data hash map)\n",
    "        # manifest_path = os.path.join(base_output_dir, f\"{sector_name}__{target}__manifest.json\")\n",
    "        # manifest = ManifestWriter(manifest_path)\n",
    "        # manifest.write(\n",
    "        #     source_paths=None,\n",
    "        #     inputs_hash=hash_df_map(merged=merged_proc),\n",
    "        #     rows=len(merged_proc),\n",
    "        #     cols=merged_proc.shape[1],\n",
    "        #     config={\"sector\": sector_name, \"target\": target}\n",
    "        # )\n",
    "        \n",
    "        # 5) Save\n",
    "        out_path = os.path.join(base_output_dir, f\"{sector_name}__{target}.csv\")\n",
    "        merged_proc.to_csv(out_path, index=True)\n",
    "        print(f\"Saved {sector_name}::{target} → {out_path} rows={len(merged_proc):,} cols={merged_proc.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

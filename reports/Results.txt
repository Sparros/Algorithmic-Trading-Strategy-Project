--- Final Experiment Results with Stock Only Data Summary ---
                 Model  Window  Threshold  Test_F1_1  Test_Recall_1  Test_Precision_1
0             CatBoost       7      0.015   0.512195       0.640244          0.426829
1              XGBoost       5      0.010   0.469767       0.543011          0.413934
2              XGBoost       7      0.015   0.465686       0.579268          0.389344
3             CatBoost       5      0.010   0.461538       0.500000          0.428571
4             CatBoost      10      0.020   0.444444       0.525641          0.384977
5              XGBoost      10      0.020   0.434109       0.538462          0.363636
6         RandomForest       7      0.015   0.419263       0.451220          0.391534
7              XGBoost       3      0.005   0.417476       0.417476          0.417476
8             CatBoost       3      0.005   0.387097       0.378641          0.395939
9         RandomForest       3      0.005   0.379679       0.344660          0.422619
10        RandomForest      10      0.020   0.376543       0.391026          0.363095
11        RandomForest       5      0.010   0.368421       0.338710          0.403846
12  LogisticRegression       5      0.010   0.364146       0.349462          0.380117
13  LogisticRegression      10      0.020   0.353659       0.371795          0.337209
14  LogisticRegression       3      0.005   0.262069       0.184466          0.452381
15  LogisticRegression       7      0.015   0.146789       0.097561          0.296296



--- Final Experiment Results with Stock and Macro Data Summary ---
                 Model  Window  Threshold  Test_Accuracy  Test_Precision_1  Test_Recall_1  Test_F1_1                                                                                          Best_Params
0   LogisticRegression      10      0.005       0.548708          0.517467       0.975309   0.676177                                                                    {'C': 0.1, 'solver': 'liblinear'}
1   LogisticRegression      10      0.010       0.491054          0.454348       0.976636   0.620178                                                                    {'C': 1.0, 'solver': 'liblinear'}
2   LogisticRegression       5      0.005       0.497018          0.465596       0.910314   0.616085                                                                    {'C': 1.0, 'solver': 'liblinear'}
3              XGBoost      10      0.005       0.574553          0.560166       0.555556   0.557851  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 0.9681620839363242}
4   LogisticRegression       5      0.010       0.415507          0.386555       0.989247   0.555891                                                                   {'C': 10.0, 'solver': 'liblinear'}
5             CatBoost      10      0.010       0.560636          0.487085       0.616822   0.544330      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 1.3011844331641287}
6         RandomForest      10      0.005       0.528827          0.512500       0.506173   0.509317                                                                {'max_depth': 5, 'n_estimators': 100}
7         RandomForest      10      0.010       0.572565          0.497674       0.500000   0.498834                                                                {'max_depth': 5, 'n_estimators': 200}
8              XGBoost      10      0.010       0.566600          0.490654       0.490654   0.490654  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 1.3011844331641287}
9             CatBoost       5      0.005       0.528827          0.468468       0.466368   0.467416      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 1.2077922077922079}
10            CatBoost       5      0.010       0.556660          0.417040       0.500000   0.454768      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 1.8783068783068784}
11             XGBoost       5      0.005       0.544732          0.484694       0.426009   0.453461  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 1.2077922077922079}
12        RandomForest       5      0.005       0.532803          0.470874       0.434978   0.452214                                                                {'max_depth': 5, 'n_estimators': 100}
13        RandomForest       5      0.010       0.578529          0.435000       0.467742   0.450777                                                                {'max_depth': 5, 'n_estimators': 100}
14             XGBoost       5      0.010       0.566600          0.423810       0.478495   0.449495  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 1.8783068783068784}
15            CatBoost      10      0.005       0.526839          0.514451       0.366255   0.427885      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 0.9681620839363242}


--- Starting Time-Series Cross-Validation for LogisticRegression ---
Fold 1/5: Training on 455 samples, testing on 453 samples
Fold 2/5: Training on 908 samples, testing on 453 samples
Fold 3/5: Training on 1361 samples, testing on 453 samples
Fold 4/5: Training on 1814 samples, testing on 453 samples
Fold 5/5: Training on 2267 samples, testing on 453 samples

--- Cross-Validation Results Summary ---
Average accuracy: 0.4614 (+/- 0.0314)
Average precision: 0.3984 (+/- 0.2084)
Average recall: 0.3476 (+/- 0.3607)
Average f1: 0.3015 (+/- 0.2216)
Best params per fold: [{'C': 0.5, 'solver': 'liblinear'}, {'C': 0.05, 'solver': 'liblinear'}, {'C': 0.1, 'solver': 'liblinear'}, {'C': 0.5, 'solver': 'liblinear'}, {'C': 1.0, 'solver': 'liblinear'}]

--- Final Model Evaluation on Unseen Test Data for LogisticRegression ---
Best parameters found: {'C': 0.5, 'solver': 'liblinear'}
Best cross-validation score: 0.39

--- Final Classification Report ---
              precision    recall  f1-score   support

           0       0.87      0.16      0.27       250
           1       0.53      0.98      0.69       243

    accuracy                           0.56       493
   macro avg       0.70      0.57      0.48       493
weighted avg       0.70      0.56      0.48       493


--- Starting Time-Series Cross-Validation for XGBoost ---
Fold 1/5: Training on 455 samples, testing on 453 samples
c:\Users\epoch_bpjmdqk\Documents\Code\venv\Lib\site-packages\xgboost\training.py:183: UserWarning: [14:20:31] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Fold 2/5: Training on 908 samples, testing on 453 samples
c:\Users\epoch_bpjmdqk\Documents\Code\venv\Lib\site-packages\xgboost\training.py:183: UserWarning: [14:20:57] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Fold 3/5: Training on 1361 samples, testing on 453 samples
c:\Users\epoch_bpjmdqk\Documents\Code\venv\Lib\site-packages\xgboost\training.py:183: UserWarning: [14:21:24] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Fold 4/5: Training on 1814 samples, testing on 453 samples
c:\Users\epoch_bpjmdqk\Documents\Code\venv\Lib\site-packages\xgboost\training.py:183: UserWarning: [14:21:54] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)
Fold 5/5: Training on 2267 samples, testing on 453 samples
c:\Users\epoch_bpjmdqk\Documents\Code\venv\Lib\site-packages\xgboost\training.py:183: UserWarning: [14:22:23] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)

--- Cross-Validation Results Summary ---
Average accuracy: 0.4751 (+/- 0.0526)
Average precision: 0.3822 (+/- 0.2132)
Average recall: 0.2083 (+/- 0.1191)
Average f1: 0.2659 (+/- 0.1461)
Best params per fold: [{'colsample_bytree': 0.8, 'learning_rate': 0.08, 'max_depth': 4, 'n_estimators': 125, 'subsample': 1.0}, {'colsample_bytree': 0.8, 'learning_rate': 0.12, 'max_depth': 3, 'n_estimators': 75, 'subsample': 0.8}, {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150, 'subsample': 0.8}, {'colsample_bytree': 0.8, 'learning_rate': 0.12, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}, {'colsample_bytree': 0.8, 'learning_rate': 0.12, 'max_depth': 4, 'n_estimators': 75, 'subsample': 1.0}]
c:\Users\epoch_bpjmdqk\Documents\Code\venv\Lib\site-packages\xgboost\training.py:183: UserWarning: [14:23:36] WARNING: C:\actions-runner\_work\xgboost\xgboost\src\learner.cc:738: 
Parameters: { "use_label_encoder" } are not used.

  bst.update(dtrain, iteration=i, fobj=obj)

--- Final Model Evaluation on Unseen Test Data for XGBoost ---
Best parameters found: {'colsample_bytree': 0.8, 'learning_rate': 0.12, 'max_depth': 4, 'n_estimators': 150, 'subsample': 1.0}
Best cross-validation score: 0.43

--- Final Classification Report ---
              precision    recall  f1-score   support

           0       0.57      0.58      0.58       250
           1       0.56      0.55      0.55       243

    accuracy                           0.57       493
   macro avg       0.57      0.57      0.57       493
weighted avg       0.57      0.57      0.57       493


--- Starting Time-Series Cross-Validation for CatBoost ---
Fold 1/5: Training on 455 samples, testing on 453 samples
Fold 2/5: Training on 908 samples, testing on 453 samples
Fold 3/5: Training on 1361 samples, testing on 453 samples
Fold 4/5: Training on 1814 samples, testing on 453 samples
Fold 5/5: Training on 2267 samples, testing on 453 samples

--- Cross-Validation Results Summary ---
Average accuracy: 0.5002 (+/- 0.0529)
Average precision: 0.5327 (+/- 0.3203)
Average recall: 0.1848 (+/- 0.2263)
Average f1: 0.2103 (+/- 0.2088)
Best params per fold: [{'depth': 3, 'learning_rate': 0.08, 'n_estimators': 150}, {'depth': 4, 'learning_rate': 0.12, 'n_estimators': 75}, {'depth': 3, 'learning_rate': 0.12, 'n_estimators': 125}, {'depth': 4, 'learning_rate': 0.12, 'n_estimators': 75}, {'depth': 3, 'learning_rate': 0.12, 'n_estimators': 100}]

--- Final Model Evaluation on Unseen Test Data for CatBoost ---
Best parameters found: {'depth': 4, 'learning_rate': 0.12, 'n_estimators': 150}
Best cross-validation score: 0.44

--- Final Classification Report ---
              precision    recall  f1-score   support

           0       0.52      0.55      0.53       250
           1       0.51      0.48      0.49       243

    accuracy                           0.52       493
   macro avg       0.51      0.51      0.51       493
weighted avg       0.51      0.52      0.51       493


--- Starting Time-Series Cross-Validation for RandomForest ---
Fold 1/5: Training on 455 samples, testing on 453 samples
Fold 2/5: Training on 908 samples, testing on 453 samples
Fold 3/5: Training on 1361 samples, testing on 453 samples
Fold 4/5: Training on 1814 samples, testing on 453 samples
Fold 5/5: Training on 2267 samples, testing on 453 samples

--- Cross-Validation Results Summary ---
Average accuracy: 0.5064 (+/- 0.0556)
Average precision: 0.3088 (+/- 0.2574)
Average recall: 0.2093 (+/- 0.3615)
Average f1: 0.1799 (+/- 0.2617)
Best params per fold: [{'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}, {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}, {'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 250}]

--- Final Model Evaluation on Unseen Test Data for RandomForest ---
Best parameters found: {'max_depth': 6, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}
Best cross-validation score: 0.39

--- Final Classification Report ---
              precision    recall  f1-score   support

           0       0.58      0.66      0.62       250
           1       0.59      0.51      0.55       243

    accuracy                           0.59       493
   macro avg       0.59      0.59      0.58       493
weighted avg       0.59      0.59      0.58       493



--- Final Coarse Modeling Results Summary - Consumer Staples Data ---
   Feature_Set          Target_Type  Window             Model  Test_Performance                             Best_Params
3        pca_3               binary       5           XGBoost            0.4702   {'max_depth': 5, 'n_estimators': 100}
7    pruned_10               binary       5          CatBoost            0.4424       {'depth': 3, 'n_estimators': 100}
4        pca_3               binary       5          CatBoost            0.4304        {'depth': 5, 'n_estimators': 50}
6    pruned_10               binary       5           XGBoost            0.4113    {'max_depth': 5, 'n_estimators': 50}
8    pruned_10               binary       5      RandomForest            0.4080   {'max_depth': 5, 'n_estimators': 100}
5        pca_3               binary       5      RandomForest            0.4019   {'max_depth': 5, 'n_estimators': 100}
1     baseline               binary       5          CatBoost            0.3798        {'depth': 5, 'n_estimators': 50}
0     baseline               binary       5           XGBoost            0.3578    {'max_depth': 3, 'n_estimators': 50}
2     baseline               binary       5      RandomForest            0.3467   {'max_depth': 10, 'n_estimators': 50}
16   pruned_10          multi_class       5          CatBoost            0.3122       {'depth': 5, 'n_estimators': 100}
17   pruned_10          multi_class       5      RandomForest            0.2585  {'max_depth': 10, 'n_estimators': 100}
13       pca_3          multi_class       5          CatBoost            0.2581       {'depth': 5, 'n_estimators': 100}
12       pca_3          multi_class       5           XGBoost            0.2359   {'max_depth': 5, 'n_estimators': 100}
14       pca_3          multi_class       5      RandomForest            0.2136  {'max_depth': 10, 'n_estimators': 100}
15   pruned_10          multi_class       5           XGBoost            0.2002    {'max_depth': 5, 'n_estimators': 50}
25   pruned_10  multi_class_extreme       5          CatBoost            0.1895        {'depth': 5, 'n_estimators': 50}
21       pca_3  multi_class_extreme       5           XGBoost            0.1783   {'max_depth': 5, 'n_estimators': 100}
26   pruned_10  multi_class_extreme       5      RandomForest            0.1780   {'max_depth': 10, 'n_estimators': 50}
10    baseline          multi_class       5          CatBoost            0.1773        {'depth': 5, 'n_estimators': 50}
9     baseline          multi_class       5           XGBoost            0.1668    {'max_depth': 3, 'n_estimators': 50}
24   pruned_10  multi_class_extreme       5           XGBoost            0.1624   {'max_depth': 5, 'n_estimators': 100}
23       pca_3  multi_class_extreme       5      RandomForest            0.1553   {'max_depth': 10, 'n_estimators': 50}
19    baseline  multi_class_extreme       5          CatBoost            0.1399       {'depth': 5, 'n_estimators': 100}
11    baseline          multi_class       5      RandomForest            0.1390   {'max_depth': 10, 'n_estimators': 50}
18    baseline  multi_class_extreme       5           XGBoost            0.1369    {'max_depth': 5, 'n_estimators': 50}
22       pca_3  multi_class_extreme       5          CatBoost            0.1352       {'depth': 5, 'n_estimators': 100}
20    baseline  multi_class_extreme       5      RandomForest            0.1160   {'max_depth': 10, 'n_estimators': 50}
28    baseline           regression       5  LinearRegression            0.0722                                      {}
27    baseline           regression       5           XGBoost            0.0568    {'max_depth': 5, 'n_estimators': 50}
29       pca_3           regression       5           XGBoost            0.0363    {'max_depth': 3, 'n_estimators': 50}
31   pruned_10           regression       5           XGBoost            0.0304    {'max_depth': 5, 'n_estimators': 50}
32   pruned_10           regression       5  LinearRegression            0.0294                                      {}
30       pca_3           regression       5  LinearRegression            0.0279                                      {}
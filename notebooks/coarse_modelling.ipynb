{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0cb29ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from src.stock_features import create_target_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cfe2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared data\n",
    "data = pd.read_csv(r'C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\stock_and_macro.csv', index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2f5614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DEFINE YOUR EXPERIMENTS ---\n",
    "experiment_configs = [\n",
    "    {\n",
    "        'model_name': 'XGBoost',\n",
    "        'model_class': XGBClassifier,\n",
    "        'initial_params': {'eval_metric': 'logloss', 'random_state': 42},\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100], \n",
    "            'learning_rate': [0.1], \n",
    "            'max_depth': [3],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'CatBoost',\n",
    "        'model_class': CatBoostClassifier,\n",
    "        'initial_params': {'verbose': False, 'random_state': 42, 'early_stopping_rounds': 50},\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100], \n",
    "            'learning_rate': [0.1], \n",
    "            'depth': [3],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'RandomForest',\n",
    "        'model_class': RandomForestClassifier,\n",
    "        'initial_params': {'random_state': 42, 'class_weight': 'balanced'},\n",
    "        'param_grid': {\n",
    "            'n_estimators': [100, 200], \n",
    "            'max_depth': [5, 10],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'LogisticRegression',\n",
    "        'model_class': LogisticRegression,\n",
    "        'initial_params': {'random_state': 42, 'class_weight': 'balanced'},\n",
    "        'param_grid': {\n",
    "            'C': [0.1, 1.0, 10.0], \n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the different hyperparameters for the data preparation step\n",
    "window_sizes = [5, 10]\n",
    "thresholds = [0.005, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29f60109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data setup for Window=5, Threshold=0.005 ---\n",
      "Class imbalance ratio (0/1): 1.21\n",
      "-> Running model: XGBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - COST_SMA_50: 0.0193\n",
      "   - Close_^GSPC: 0.0170\n",
      "   - PAYEMS: 0.0129\n",
      "   - PG_Volume_MA_20D: 0.0116\n",
      "   - COST_MACD_Hist: 0.0113\n",
      "   - KO_EMA_12: 0.0113\n",
      "   - PEP_MACD_Line: 0.0107\n",
      "   - Close_PG_lag3: 0.0104\n",
      "   - WMT_vs_KO_CloseRatio: 0.0101\n",
      "   - COST_Stoch_D_14_3: 0.0098\n",
      "-> Running model: CatBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - COST_MACD_Signal: 4.1033\n",
      "   - PG_MACD_Signal: 3.4915\n",
      "   - WMT_Volume_MA_20D: 3.4832\n",
      "   - WMT_vs_PEP_CloseRatio: 2.8758\n",
      "   - KO_MinusDI_14: 2.5564\n",
      "   - DGS10: 2.5164\n",
      "   - COST_DX_14: 1.9605\n",
      "   - ^GSPC_DX_14: 1.7048\n",
      "   - ^GSPC_RSI14_lag3: 1.6525\n",
      "   - WMT_OBV: 1.5586\n",
      "-> Running model: RandomForest\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - COST_MACD_Signal: 0.0224\n",
      "   - WMT_MACD_Line: 0.0170\n",
      "   - ^GSPC_BB_PctB20: 0.0166\n",
      "   - WMT_vs_KO_CloseRatio: 0.0159\n",
      "   - ^GSPC_RSI14_lag3: 0.0158\n",
      "   - WMT_Volume_MA_20D: 0.0139\n",
      "   - DGS10: 0.0128\n",
      "   - PG_BB_Bandwidth20: 0.0122\n",
      "   - ^GSPC_MACD_Line: 0.0118\n",
      "   - ^GSPC_ADX_14: 0.0115\n",
      "-> Running model: LogisticRegression\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - PEP_Volume_MA_20D: 0.0000\n",
      "   - Volume_COST: 0.0000\n",
      "   - COST_Volume_MA_20D: 0.0000\n",
      "   - Volume_PEP: 0.0000\n",
      "   - KO_Volume_MA_20D: 0.0000\n",
      "   - WMT_vs_^GSPC_RelStrength: 0.0000\n",
      "   - Volume_PG: 0.0000\n",
      "   - Volume_WMT: 0.0000\n",
      "   - WMT_Volume_MA_20D: 0.0000\n",
      "   - COST_OBV: 0.0000\n",
      "\n",
      "--- Data setup for Window=5, Threshold=0.01 ---\n",
      "Class imbalance ratio (0/1): 1.88\n",
      "-> Running model: XGBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - ^GSPC_Stoch_D_14_3: 0.0147\n",
      "   - Close_^GSPC: 0.0139\n",
      "   - ^GSPC_MACD_Line: 0.0124\n",
      "   - KO_MACD_Signal: 0.0112\n",
      "   - KO_SMA_50: 0.0108\n",
      "   - ^GSPC_Stoch_K_14: 0.0105\n",
      "   - Close_WMT_lag1: 0.0103\n",
      "   - ^GSPC_BB_PctB20: 0.0100\n",
      "   - ^GSPC_RSI14_lag3: 0.0100\n",
      "   - WMT_BB_PctB20: 0.0099\n",
      "-> Running model: CatBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - COST_MACD_Signal: 4.3132\n",
      "   - KO_MACD_Hist: 2.8348\n",
      "   - WMT_MACD_Line: 2.7572\n",
      "   - PG_BB_Bandwidth20: 2.6864\n",
      "   - PEP_ADX_14: 2.6549\n",
      "   - KO_EMA_26: 2.5714\n",
      "   - ^GSPC_MACD_Line: 2.3344\n",
      "   - COST_MACD_Line: 1.8974\n",
      "   - WMT_Volume_MA_20D: 1.7984\n",
      "   - ^GSPC_RSI14_lag3: 1.7835\n",
      "-> Running model: RandomForest\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - ^GSPC_MACD_Line: 0.0233\n",
      "   - PG_BB_Bandwidth20: 0.0204\n",
      "   - COST_MACD_Signal: 0.0183\n",
      "   - ^GSPC_MACD_Hist: 0.0170\n",
      "   - ^GSPC_RSI14_lag3: 0.0167\n",
      "   - ^GSPC_RSI14_lag5: 0.0164\n",
      "   - ^GSPC_BB_PctB20: 0.0164\n",
      "   - ^GSPC_MACD_Signal: 0.0162\n",
      "   - WMT_MACD_Line: 0.0144\n",
      "   - DGS10: 0.0120\n",
      "-> Running model: LogisticRegression\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - PEP_Volume_MA_20D: 0.0000\n",
      "   - Volume_COST: 0.0000\n",
      "   - KO_Volume_MA_20D: 0.0000\n",
      "   - WMT_Volume_MA_20D: 0.0000\n",
      "   - Volume_PEP: 0.0000\n",
      "   - WMT_vs_^GSPC_RelStrength: 0.0000\n",
      "   - Volume_WMT: 0.0000\n",
      "   - Volume_KO: 0.0000\n",
      "   - WMT_Volume_x_ATR: 0.0000\n",
      "   - Volume_PG: 0.0000\n",
      "\n",
      "--- Data setup for Window=10, Threshold=0.005 ---\n",
      "Class imbalance ratio (0/1): 0.97\n",
      "-> Running model: XGBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - PEP_SMA_20: 0.0209\n",
      "   - COST_EMA_26: 0.0190\n",
      "   - PG_OBV: 0.0187\n",
      "   - ^GSPC_BB_Lower20: 0.0171\n",
      "   - ^GSPC_MACD_Signal: 0.0158\n",
      "   - PEP_OBV: 0.0146\n",
      "   - WMT_vs_KO_CloseRatio: 0.0146\n",
      "   - KO_EMA_12: 0.0145\n",
      "   - PAYEMS: 0.0142\n",
      "   - KO_SMA_50: 0.0132\n",
      "-> Running model: CatBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - WMT_vs_KO_CloseRatio: 5.0811\n",
      "   - WMT_Volume_MA_20D: 3.9099\n",
      "   - COST_Volume_MA_20D: 3.7907\n",
      "   - PG_MACD_Line: 3.2798\n",
      "   - WMT_vs_PEP_CloseRatio: 3.1645\n",
      "   - DGS10: 2.5077\n",
      "   - ^GSPC_MACD_Signal: 2.4221\n",
      "   - WMT_MACD_Hist: 2.4059\n",
      "   - PEP_Volume_MA_20D: 2.1405\n",
      "   - PG_BB_Middle20: 1.8402\n",
      "-> Running model: RandomForest\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - WMT_Volume_MA_20D: 0.0283\n",
      "   - DGS10: 0.0166\n",
      "   - ^GSPC_MACD_Hist: 0.0152\n",
      "   - COST_MACD_Line: 0.0145\n",
      "   - COST_MACD_Signal: 0.0142\n",
      "   - WMT_vs_KO_CloseRatio: 0.0139\n",
      "   - WMT_SMA_50: 0.0131\n",
      "   - KO_BB_Middle20: 0.0125\n",
      "   - ^GSPC_BB_PctB20: 0.0124\n",
      "   - CPIAUCSL: 0.0113\n",
      "-> Running model: LogisticRegression\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - PEP_Volume_MA_20D: 0.0000\n",
      "   - Volume_COST: 0.0000\n",
      "   - COST_Volume_MA_20D: 0.0000\n",
      "   - Volume_PG: 0.0000\n",
      "   - WMT_vs_^GSPC_RelStrength: 0.0000\n",
      "   - KO_Volume_MA_20D: 0.0000\n",
      "   - PG_Volume_MA_20D: 0.0000\n",
      "   - Volume_WMT: 0.0000\n",
      "   - COST_OBV: 0.0000\n",
      "   - Volume_PEP: 0.0000\n",
      "\n",
      "--- Data setup for Window=10, Threshold=0.01 ---\n",
      "Class imbalance ratio (0/1): 1.30\n",
      "-> Running model: XGBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - WMT_BB_Lower20: 0.0273\n",
      "   - KO_BB_Upper20: 0.0236\n",
      "   - PAYEMS: 0.0192\n",
      "   - Open_PEP: 0.0166\n",
      "   - CPIAUCSL: 0.0161\n",
      "   - PG_OBV: 0.0128\n",
      "   - WMT_SMA_50: 0.0127\n",
      "   - PG_BB_Lower20: 0.0126\n",
      "   - ^GSPC_MACD_Hist: 0.0125\n",
      "   - PEP_EMA_26: 0.0124\n",
      "-> Running model: CatBoost\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - WMT_vs_KO_CloseRatio: 4.1102\n",
      "   - WMT_Volume_MA_20D: 3.5646\n",
      "   - COST_MACD_Signal: 3.1925\n",
      "   - DGS10: 2.6850\n",
      "   - ^GSPC_MACD_Signal: 2.6515\n",
      "   - WMT_MACD_Line: 2.6411\n",
      "   - COST_Volume_MA_20D: 2.5456\n",
      "   - WMT_MACD_Hist: 2.2906\n",
      "   - CPIAUCSL: 2.2282\n",
      "   - COST_MACD_Line: 1.8188\n",
      "-> Running model: RandomForest\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - WMT_MACD_Line: 0.0228\n",
      "   - WMT_Volume_MA_20D: 0.0175\n",
      "   - ^GSPC_BB_PctB20: 0.0169\n",
      "   - ^GSPC_MACD_Line: 0.0161\n",
      "   - ^GSPC_MACD_Hist: 0.0152\n",
      "   - ^GSPC_PlusDI_14: 0.0151\n",
      "   - PG_MACD_Line: 0.0150\n",
      "   - WMT_vs_KO_CloseRatio: 0.0148\n",
      "   - COST_MACD_Signal: 0.0129\n",
      "   - DGS10: 0.0128\n",
      "-> Running model: LogisticRegression\n",
      "   Top 10 Features (or Coefficients):\n",
      "   - PEP_Volume_MA_20D: 0.0000\n",
      "   - WMT_vs_^GSPC_RelStrength: 0.0000\n",
      "   - Volume_PG: 0.0000\n",
      "   - Volume_COST: 0.0000\n",
      "   - COST_Volume_MA_20D: 0.0000\n",
      "   - Volume_PEP: 0.0000\n",
      "   - Volume_WMT: 0.0000\n",
      "   - WMT_Volume_x_ATR: 0.0000\n",
      "   - PG_Volume_MA_20D: 0.0000\n",
      "   - COST_OBV: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# --- 2. THE EXPERIMENTAL LOOP (STAGE 1: MODEL SCREENING) ---\n",
    "results = []\n",
    "target_ticker = 'WMT'\n",
    "split_date = '2021-01-01'\n",
    "\n",
    "for window in window_sizes:\n",
    "    for threshold in thresholds:\n",
    "        # A. Dynamically create the target variable for this experiment\n",
    "        data_target = create_target_variable(data.copy(), target_ticker, window=window, threshold=threshold)\n",
    "\n",
    "        # B. Separate features (X) and target (y)\n",
    "        target_col_name = f'{target_ticker}_Target'\n",
    "        # Dynamically create the target return column name to match the function's output\n",
    "        target_return_col_name = f'{target_ticker}_target_return_{window}D_{threshold}'\n",
    "        \n",
    "        columns_to_drop = [\n",
    "            target_col_name,\n",
    "            target_return_col_name,\n",
    "            f'Open_{target_ticker}',\n",
    "            f'High_{target_ticker}',\n",
    "            f'Low_{target_ticker}',\n",
    "            f'Close_{target_ticker}'\n",
    "        ]\n",
    "\n",
    "        X = data_target.drop(columns=columns_to_drop)\n",
    "        y = data_target[target_col_name]\n",
    "        \n",
    "        X_train = X.loc[:split_date].copy()\n",
    "        y_train = y.loc[:split_date].copy()\n",
    "        X_test = X.loc[split_date:].copy()\n",
    "        y_test = y.loc[split_date:].copy()\n",
    "\n",
    "        # C. Handle Class Imbalance\n",
    "        neg_to_pos_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "        print(f\"\\n--- Data setup for Window={window}, Threshold={threshold} ---\")\n",
    "        print(f\"Class imbalance ratio (0/1): {neg_to_pos_ratio:.2f}\")\n",
    "\n",
    "        for exp in experiment_configs:\n",
    "            print(f\"-> Running model: {exp['model_name']}\")\n",
    "            \n",
    "            # Create a new model instance for this run\n",
    "            model = exp['model_class'](**exp['initial_params'])\n",
    "            \n",
    "            # Get the param_grid and add the scale_pos_weight if necessary\n",
    "            param_grid = exp['param_grid'].copy()\n",
    "            if exp['model_name'] in ['XGBoost', 'CatBoost']:\n",
    "                param_grid['scale_pos_weight'] = [neg_to_pos_ratio]\n",
    "\n",
    "            # D. Fit with a lightweight GridSearchCV\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                scoring='f1_macro',\n",
    "                cv=3,\n",
    "                verbose=0,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "\n",
    "            # E. Evaluate the model and collect results\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            \n",
    "            # F. Extract and store top features\n",
    "            top_features = {}\n",
    "            if hasattr(best_model, 'feature_importances_'):\n",
    "                importances = pd.Series(best_model.feature_importances_, index=X_train.columns)\n",
    "                top_features = importances.nlargest(10).to_dict()\n",
    "            elif hasattr(best_model, 'coef_'):\n",
    "                coefficients = pd.Series(best_model.coef_[0], index=X_train.columns)\n",
    "                top_features = coefficients.abs().nlargest(10).to_dict()\n",
    "            \n",
    "            print(\"   Top 10 Features (or Coefficients):\")\n",
    "            for feature, score in top_features.items():\n",
    "                print(f\"   - {feature}: {score:.4f}\")\n",
    "            \n",
    "            results.append({\n",
    "                'Model': exp['model_name'],\n",
    "                'Window': window,\n",
    "                'Threshold': threshold,\n",
    "                'Test_Accuracy': report['accuracy'],\n",
    "                'Test_Precision_1': report['1']['precision'],\n",
    "                'Test_Recall_1': report['1']['recall'],\n",
    "                'Test_F1_1': report['1']['f1-score'],\n",
    "                'Best_Params': grid_search.best_params_,\n",
    "                'Top_Features': top_features\n",
    "            })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c0891bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Experiment Results Summary ---\n",
      "                 Model  Window  Threshold  Test_Accuracy  Test_Precision_1  Test_Recall_1  Test_F1_1                                                                                          Best_Params\n",
      "0   LogisticRegression      10      0.005       0.548708          0.517467       0.975309   0.676177                                                                    {'C': 0.1, 'solver': 'liblinear'}\n",
      "1   LogisticRegression      10      0.010       0.491054          0.454348       0.976636   0.620178                                                                    {'C': 1.0, 'solver': 'liblinear'}\n",
      "2   LogisticRegression       5      0.005       0.497018          0.465596       0.910314   0.616085                                                                    {'C': 1.0, 'solver': 'liblinear'}\n",
      "3              XGBoost      10      0.005       0.574553          0.560166       0.555556   0.557851  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 0.9681620839363242}\n",
      "4   LogisticRegression       5      0.010       0.415507          0.386555       0.989247   0.555891                                                                   {'C': 10.0, 'solver': 'liblinear'}\n",
      "5             CatBoost      10      0.010       0.560636          0.487085       0.616822   0.544330      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 1.3011844331641287}\n",
      "6         RandomForest      10      0.005       0.528827          0.512500       0.506173   0.509317                                                                {'max_depth': 5, 'n_estimators': 100}\n",
      "7         RandomForest      10      0.010       0.572565          0.497674       0.500000   0.498834                                                                {'max_depth': 5, 'n_estimators': 200}\n",
      "8              XGBoost      10      0.010       0.566600          0.490654       0.490654   0.490654  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 1.3011844331641287}\n",
      "9             CatBoost       5      0.005       0.528827          0.468468       0.466368   0.467416      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 1.2077922077922079}\n",
      "10            CatBoost       5      0.010       0.556660          0.417040       0.500000   0.454768      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 1.8783068783068784}\n",
      "11             XGBoost       5      0.005       0.544732          0.484694       0.426009   0.453461  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 1.2077922077922079}\n",
      "12        RandomForest       5      0.005       0.532803          0.470874       0.434978   0.452214                                                                {'max_depth': 5, 'n_estimators': 100}\n",
      "13        RandomForest       5      0.010       0.578529          0.435000       0.467742   0.450777                                                                {'max_depth': 5, 'n_estimators': 100}\n",
      "14             XGBoost       5      0.010       0.566600          0.423810       0.478495   0.449495  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'scale_pos_weight': 1.8783068783068784}\n",
      "15            CatBoost      10      0.005       0.526839          0.514451       0.366255   0.427885      {'depth': 3, 'learning_rate': 0.1, 'n_estimators': 100, 'scale_pos_weight': 0.9681620839363242}\n"
     ]
    }
   ],
   "source": [
    "# --- 3. DISPLAY FINAL RESULTS ---\n",
    "results_df = pd.DataFrame(results)\n",
    "# Sort the results by F1 score in descending order and reset the index\n",
    "results_df = results_df.sort_values(by='Test_F1_1', ascending=False).reset_index(drop=True)\n",
    "results_df.drop(columns=['Top_Features'], inplace=True)  # Drop top features for cleaner output\n",
    "print(\"\\n--- Final Experiment Results Summary ---\")\n",
    "print(results_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

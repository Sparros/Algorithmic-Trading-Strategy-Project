{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb29ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from stock_features import prepare_data_for_ml, create_target_variable\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for your data pipeline\n",
    "tickers_list = ['PG', 'KO', 'PEP', 'WMT', 'COST', '^GSPC']\n",
    "start_date_str = '1986-01-01'\n",
    "end_date_str = '2023-01-01'\n",
    "output_filename = \"consumer_stocks_final_engineered.csv\"\n",
    "\n",
    "# Make the single function call to run the entire pipeline\n",
    "final_engineered_df = prepare_data_for_ml(\n",
    "    tickers=tickers_list,\n",
    "    start_date=start_date_str,\n",
    "    end_date=end_date_str,\n",
    "    output_engineered_csv=output_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DEFINE YOUR EXPERIMENTS ---\n",
    "# Add new experiments by expanding this list\n",
    "experiments = [\n",
    "    # XGBoost with a weekly target and 1% threshold\n",
    "    {'model': 'XGBoost', 'window': 5, 'threshold': 0.01, 'model_params': {}},\n",
    "    \n",
    "    # Random Forest with a weekly target and 1% threshold\n",
    "    {'model': 'RandomForest', 'window': 5, 'threshold': 0.01, 'model_params': {}},\n",
    "\n",
    "    # Let's try a different target definition: shorter window, lower threshold\n",
    "    {'model': 'XGBoost', 'window': 3, 'threshold': 0.005, 'model_params': {}},\n",
    "    {'model': 'RandomForest', 'window': 3, 'threshold': 0.005, 'model_params': {}},\n",
    "\n",
    "    # Let's try a different target definition: longer window, higher threshold\n",
    "    {'model': 'XGBoost', 'window': 10, 'threshold': 0.02, 'model_params': {}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f60109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. THE EXPERIMENTAL LOOP ---\n",
    "results = []\n",
    "target_ticker = 'WMT'\n",
    "\n",
    "for exp in experiments:\n",
    "    print(f\"\\n--- Running experiment: Model={exp['model']}, Window={exp['window']}, Threshold={exp['threshold']} ---\")\n",
    "\n",
    "    # A. Dynamically create the target variable for this experiment\n",
    "    data_target = create_target_variable(final_engineered_df.copy(), target_ticker, window=exp['window'], threshold=exp['threshold'])\n",
    "    \n",
    "    # B. Separate features (X) and target (y)\n",
    "    target_col_name = f'{target_ticker}_Target'\n",
    "    target_return_col_name = [col for col in data_target.columns if col.startswith(f'{target_ticker}_target_return_')][0]\n",
    "    \n",
    "    columns_to_drop = [target_col_name, target_return_col_name, f'Open_{target_ticker}', f'High_{target_ticker}', f'Low_{target_ticker}', f'Close_{target_ticker}']\n",
    "    \n",
    "    X = data_target.drop(columns=columns_to_drop)\n",
    "    y = data_target[target_col_name]\n",
    "    \n",
    "    X_train = X.loc[:'2021-01-01'].copy()\n",
    "    y_train = y.loc[:'2021-01-01'].copy()\n",
    "    X_test = X.loc['2021-01-01':].copy()\n",
    "    y_test = y.loc['2021-01-01':].copy()\n",
    "    \n",
    "    # C. Handle Class Imbalance\n",
    "    neg_to_pos_ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    print(f\"Class imbalance ratio (0/1): {neg_to_pos_ratio:.2f}\")\n",
    "\n",
    "    # D. Set up the correct model and GridSearchCV for this experiment\n",
    "    if exp['model'] == 'XGBoost':\n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=42, scale_pos_weight=neg_to_pos_ratio\n",
    "        )\n",
    "        param_grid = {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1], 'max_depth': [3, 5]}\n",
    "    \n",
    "    elif exp['model'] == 'RandomForest':\n",
    "        model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "        param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20], 'min_samples_leaf': [1, 5]}\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1_macro',\n",
    "        cv=3,\n",
    "        verbose=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # E. Evaluate the model and collect results\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': exp['model'],\n",
    "        'Window': exp['window'],\n",
    "        'Threshold': exp['threshold'],\n",
    "        'Test_Accuracy': report['accuracy'],\n",
    "        'Test_Precision_1': report['1']['precision'],\n",
    "        'Test_Recall_1': report['1']['recall'],\n",
    "        'Test_F1_1': report['1']['f1-score'],\n",
    "        'Best_Params': grid_search.best_params_,\n",
    "    })\n",
    "\n",
    "# --- 3. DISPLAY FINAL RESULTS ---\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n--- Final Experiment Results Summary ---\")\n",
    "print(results_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

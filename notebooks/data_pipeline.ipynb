{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca51a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "# Add the parent directory (where 'src' folder is located) to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.stock_features import build_stock_features_orchestrator, apply_kalman_filter_with_lag\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------- Output folder --------\n",
    "base_output_dir = r\"C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\"\n",
    "macro_folder = r\"C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\raw\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00248952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Sector definitions --------\n",
    "SECTORS = {\n",
    "    \"staples\": {\n",
    "        \"tickers\": [\"WMT\",\"PG\",\"KO\",\"PEP\",\"COST\",\"CL\",\"CLX\",\"KMB\",\"GIS\",\"MDLZ\",\"KR\",\"TGT\",\"XLP\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLP\",\n",
    "    },\n",
    "    \"discretionary\": {\n",
    "        \"tickers\": [\"AMZN\",\"HD\",\"MCD\",\"NKE\",\"SBUX\",\"TJX\",\"LOW\",\"BKNG\",\"ROST\",\"MAR\",\"XLY\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLY\",\n",
    "    },\n",
    "    \"healthcare\": {\n",
    "        \"tickers\": [\"UNH\",\"LLY\",\"JNJ\",\"ABBV\",\"MRK\",\"TMO\",\"ABT\",\"PFE\",\"MDT\",\"ISRG\",\"CVS\",\"HUM\",\"XLV\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLV\",\n",
    "    },\n",
    "    \"technology\": {\n",
    "        \"tickers\": [\"AAPL\",\"MSFT\",\"NVDA\",\"AVGO\",\"ADBE\",\"CRM\",\"AMD\",\"INTC\",\"CSCO\",\"QCOM\",\"ORCL\",\"TXN\",\"XLK\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLK\",\n",
    "    },\n",
    "    \"financials\": {\n",
    "        \"tickers\": [\"JPM\",\"BAC\",\"WFC\",\"MS\",\"GS\",\"C\",\"BLK\",\"PGR\",\"AXP\",\"USB\",\"SCHW\",\"CB\",\"XLF\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLF\",\n",
    "    },\n",
    "    \"energy\": {\n",
    "        \"tickers\": [\"XOM\",\"CVX\",\"COP\",\"EOG\",\"SLB\",\"OXY\",\"PSX\",\"MPC\",\"VLO\",\"HAL\",\"KMI\",\"XLE\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLE\",\n",
    "    },\n",
    "    \"industrials\": {\n",
    "        \"tickers\": [\"CAT\",\"BA\",\"HON\",\"GE\",\"UPS\",\"UNP\",\"DE\",\"RTX\",\"LMT\",\"ETN\",\"EMR\",\"MMM\",\"XLI\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLI\",\n",
    "    },\n",
    "    \"utilities\": {\n",
    "        \"tickers\": [\"NEE\",\"SO\",\"DUK\",\"AEP\",\"EXC\",\"SRE\",\"XEL\",\"D\",\"PEG\",\"ED\",\"XLU\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLU\",\n",
    "    },\n",
    "    \"materials\": {\n",
    "        \"tickers\": [\"LIN\",\"APD\",\"ECL\",\"NEM\",\"FCX\",\"NUE\",\"SHW\",\"ALB\",\"MLM\",\"VMC\",\"XLB\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLB\",\n",
    "    },\n",
    "    \"communication_services\": {\n",
    "        \"tickers\": [\"META\",\"GOOGL\",\"GOOG\",\"NFLX\",\"CMCSA\",\"DIS\",\"T\",\"VZ\",\"XLC\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLC\",\n",
    "    },\n",
    "    \"real_estate\": {\n",
    "        \"tickers\": [\"AMT\",\"PLD\",\"EQIX\",\"PSA\",\"SPG\",\"CCI\",\"O\",\"WELL\",\"XLRE\",\"^GSPC\"],\n",
    "        \"sector_etf\": \"XLRE\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf3108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing macro data from CSV.\n",
      "Data loaded: (31652, 8)\n"
     ]
    }
   ],
   "source": [
    "from src.macro_features import macro_data_orchestrator\n",
    "# (optional) date range\n",
    "start_date_str = None  \n",
    "end_date_str   = None  \n",
    "\n",
    "FRED_series_ids = {\n",
    "        'CPI': 'CPIAUCSL',\n",
    "        'FEDERAL_FUNDS_RATE': 'DFF',\n",
    "        'TREASURY_YIELD': 'DGS10',\n",
    "        'UNEMPLOYMENT': 'UNRATE',\n",
    "        'REAL_GDP': 'GDPC1',\n",
    "        'RETAIL_SALES': 'RSAFS',\n",
    "        'PAYEMS': 'PAYEMS' \n",
    "    }\n",
    "\n",
    "macro_funcs = { 'CPI', 'FEDERAL_FUNDS_RATE', 'TREASURY_YIELD', \n",
    "                'UNEMPLOYMENT', 'REAL_GDP', 'RETAIL_SALES', 'PAYEMS' }\n",
    "\n",
    "# Try load macro data, if no macro data run orchestraotr:\n",
    "try:\n",
    "    macro_df = pd.read_csv(\n",
    "        r'C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\raw\\macros.csv'\n",
    "    )\n",
    "    print(\"Loaded existing macro data from CSV.\")\n",
    "    print(f\"Data loaded: {macro_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    macro_df = macro_data_orchestrator(\n",
    "        macro_funcs_to_fetch=macro_funcs,\n",
    "        fred_series_ids_dict=FRED_series_ids,\n",
    "        start_date=start_date_str,\n",
    "        save_path=macro_folder,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building staples (14 tickers) ---\n",
      "\n",
      "--- Starting Stock Feature Pipeline ---\n",
      "Fetching data for 14 tickers...\n",
      "Date range: All available history to Current date\n",
      "Fetching full history for WMT...\n",
      "Fetching full history for PG...\n",
      "Fetching full history for KO...\n",
      "Fetching full history for PEP...\n",
      "Fetching full history for COST...\n",
      "Fetching full history for CL...\n",
      "Fetching full history for CLX...\n",
      "Fetching full history for KMB...\n",
      "Fetching full history for GIS...\n",
      "Fetching full history for MDLZ...\n",
      "Fetching full history for KR...\n",
      "Fetching full history for TGT...\n",
      "Fetching full history for XLP...\n",
      "Fetching full history for ^GSPC...\n",
      "\n",
      "Final merged DataFrame has 6090 common entries.\n",
      "\n",
      "Discovered stock prefixes: ['CL', 'CLX', 'COST', 'GIS', 'KMB', 'KO', 'KR', 'MDLZ', 'PEP', 'PG', 'TGT', 'WMT', 'XLP', '^GSPC']\n",
      "\n",
      "Processing features for stock prefix: CL\n",
      "\n",
      "Processing features for stock prefix: CLX\n",
      "\n",
      "Processing features for stock prefix: COST\n",
      "\n",
      "Processing features for stock prefix: GIS\n",
      "\n",
      "Processing features for stock prefix: KMB\n",
      "\n",
      "Processing features for stock prefix: KO\n",
      "\n",
      "Processing features for stock prefix: KR\n",
      "\n",
      "Processing features for stock prefix: MDLZ\n",
      "\n",
      "Processing features for stock prefix: PEP\n",
      "\n",
      "Processing features for stock prefix: PG\n",
      "\n",
      "Processing features for stock prefix: TGT\n",
      "\n",
      "Processing features for stock prefix: WMT\n",
      "\n",
      "Processing features for stock prefix: XLP\n",
      "\n",
      "Processing features for stock prefix: ^GSPC\n",
      "\n",
      "Applying general features...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sector_and_market_relatives() got an unexpected keyword argument 'sector_etf'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m supplier_tickers = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tickers \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {target_ticker, sector_etf, \u001b[33m\"\u001b[39m\u001b[33m^GSPC\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Building \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tickers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tickers) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mbuild_stock_features_orchestrator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_ticker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_ticker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43msupplier_tickers\u001b[49m\u001b[43m=\u001b[49m\u001b[43msupplier_tickers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbenchmark_ticker\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m^GSPC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkalman_lags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Kalman inside orchestrator\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkalman_targets\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43msector_etf\u001b[49m\u001b[43m=\u001b[49m\u001b[43msector_etf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# start_date=start_date_str,\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# end_date=end_date_str,\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Ensure timezone-naive index before merging macro\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df.index, \u001b[33m\"\u001b[39m\u001b[33mtz\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\src\\stock_features.py:978\u001b[39m, in \u001b[36mbuild_stock_features_orchestrator\u001b[39m\u001b[34m(tickers, target_ticker, supplier_tickers, benchmark_ticker, start_date, end_date, output_raw_csv, output_engineered_csv, kalman_lags, kalman_targets, sector_etf, dropna_frac)\u001b[39m\n\u001b[32m    975\u001b[39m     df = add_cross_stock_lagged_correlations(df, target_ticker, supplier)\n\u001b[32m    977\u001b[39m \u001b[38;5;66;03m# use sector ETF when provided (so this works for non-staples, too)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m df = \u001b[43msector_and_market_relatives\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msector_etf\u001b[49m\u001b[43m=\u001b[49m\u001b[43msector_etf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_bench\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m^GSPC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mClose_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_ticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mClose_KO\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n\u001b[32m    981\u001b[39m     df = add_intermarket_spread(df, target_ticker, \u001b[33m'\u001b[39m\u001b[33mKO\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: sector_and_market_relatives() got an unexpected keyword argument 'sector_etf'"
     ]
    }
   ],
   "source": [
    "# -------- Build sector datasets --------\n",
    "for sector_name, cfg in SECTORS.items():\n",
    "    tickers = cfg[\"tickers\"]\n",
    "    sector_etf = cfg.get(\"sector_etf\")\n",
    "\n",
    "    # equities = all non-index, non-ETF names\n",
    "    equities = [t for t in tickers if not t.startswith(\"^\") and t != sector_etf]\n",
    "\n",
    "    for target in equities:\n",
    "        suppliers = [t for t in equities if t != target]  # peers (exclude target)\n",
    "        print(f\"\\n--- Building {sector_name} :: target={target} ---\")\n",
    "\n",
    "        df = build_stock_features_orchestrator(\n",
    "            tickers=tickers,\n",
    "            target_ticker=target,\n",
    "            supplier_tickers=suppliers,\n",
    "            benchmark_ticker=\"^GSPC\",\n",
    "            kalman_lags=[1,5,10],           # keep inside orchestrator\n",
    "            kalman_targets=\"all\",\n",
    "            sector_etf=sector_etf,\n",
    "            dropna_frac=0.90\n",
    "        )\n",
    "\n",
    "        # make sure index is tz-naive before merging macro\n",
    "        if getattr(df.index, \"tz\", None) is not None:\n",
    "            df.index = df.index.tz_localize(None)\n",
    "\n",
    "        if not macro_df.empty:\n",
    "            merged = pd.merge(df, macro_df, left_index=True, right_index=True, how='left')\n",
    "            macro_cols = list(FRED_series_ids.values())\n",
    "            merged[macro_cols] = merged[macro_cols].shift(1)  # avoid lookahead\n",
    "        else:\n",
    "            merged = df\n",
    "\n",
    "        out_path = os.path.join(base_output_dir, f\"{sector_name}__{target}.csv\")\n",
    "        merged.to_csv(out_path, index=True)\n",
    "        print(f\"Saved {sector_name}:: {target} → {out_path}  rows={len(merged):,} cols={merged.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd184a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from src.modelling_functions import build_datasets_for_models, base_rule_ma_cross, purged_time_series_splits\n",
    "\n",
    "def _fit_with_es(pipe, X_tr, y_tr, X_va, y_va, rounds=50):\n",
    "    \"\"\"Fit pipeline with XGBoost early stopping (handles <2.0 and ≥2.0).\"\"\"\n",
    "    common = dict(model__eval_set=[(X_va, y_va)], model__verbose=False)\n",
    "    try:\n",
    "        pipe.fit(X_tr, y_tr, model__early_stopping_rounds=rounds, **common)\n",
    "    except TypeError:\n",
    "        es = xgb.callback.EarlyStopping(rounds=rounds, save_best=True)\n",
    "        pipe.fit(X_tr, y_tr, model__callbacks=[es], **common)\n",
    "    return pipe\n",
    "\n",
    "def quick_score_ticker(tkr, engineered_df, H=10, pt=1.0, sl=1.0, span_vol=20, seed=42, n_trials=40):\n",
    "    close = engineered_df[f\"Close_{tkr}\"].astype(float)\n",
    "    X_base = engineered_df.drop(\n",
    "        columns=[f'Open_{tkr}', f'High_{tkr}', f'Low_{tkr}', f'Close_{tkr}'],\n",
    "        errors='ignore'\n",
    "    )\n",
    "    base_side = base_rule_ma_cross(close, fast=10, slow=20)\n",
    "\n",
    "    packs = build_datasets_for_models(\n",
    "        X=X_base, close=close, span_vol=span_vol, H=H, pt_sl=(pt, sl), base_side=base_side\n",
    "    )\n",
    "    X, y, t1 = packs[\"meta_X\"], packs[\"meta_y\"], packs[\"meta_t1\"]\n",
    "\n",
    "    # class stats for imbalance + baseline PR\n",
    "    n_events = len(y)\n",
    "    n_pos = int(y.sum())\n",
    "    base_pr = (n_pos / n_events) if n_events else np.nan\n",
    "    cw = ((n_events - n_pos) / max(n_pos, 1))  # scale_pos_weight\n",
    "\n",
    "    def build_pipe(params, sel='median'):\n",
    "        base_est = XGBClassifier(**{**params, \"verbosity\": 0})\n",
    "        return Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"selector\", SelectFromModel(base_est, threshold=sel)),\n",
    "            (\"model\", XGBClassifier(**{**params, \"verbosity\": 0}))\n",
    "        ])\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 300, 1200),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "            \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 20.0),\n",
    "            \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "            \"scale_pos_weight\": cw,           # <- imbalance help\n",
    "            \"eval_metric\": \"logloss\",\n",
    "            \"random_state\": seed, \"n_jobs\": -1, \"tree_method\": \"hist\",\n",
    "        }\n",
    "        sel = trial.suggest_categorical(\"selector_threshold\", [\"median\", \"mean\", \"0.75*mean\"])\n",
    "        pipe = build_pipe(params, sel)\n",
    "\n",
    "        splits = list(purged_time_series_splits(X.index, t1.reindex(X.index), n_splits=3, test_size=None, embargo=H))\n",
    "        scores = []\n",
    "        for tr, va in splits:\n",
    "            X_tr, X_va = X.iloc[tr], X.iloc[va]\n",
    "            y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "            _fit_with_es(pipe, X_tr, y_tr, X_va, y_va, rounds=50)\n",
    "            p = pipe.predict_proba(X_va)[:, 1]\n",
    "            scores.append(average_precision_score(y_va, p))  # PR-AUC\n",
    "        return float(np.nanmean(scores)) if scores else -10.0\n",
    "\n",
    "    # very small samples → PR-AUC is unstable; short-circuit with NaN\n",
    "    if (n_events < 250) or (n_pos < 40):\n",
    "        return {\"ticker\": tkr, \"cv_pr_auc\": np.nan, \"n_events\": n_events, \"n_pos\": n_pos,\n",
    "                \"base_pr\": base_pr, \"lift\": np.nan}\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "    best = study.best_value\n",
    "    return {\n",
    "        \"ticker\": tkr,\n",
    "        \"cv_pr_auc\": best,\n",
    "        \"n_events\": n_events,\n",
    "        \"n_pos\": n_pos,\n",
    "        \"base_pr\": base_pr,\n",
    "        \"lift\": (best / (base_pr + 1e-12)) if np.isfinite(base_pr) and base_pr > 0 else np.nan\n",
    "    }\n",
    "\n",
    "def scan_tickers(tickers, engineered_df, n_trials=40):\n",
    "    rows = []\n",
    "    for t in tickers:\n",
    "        try:\n",
    "            rows.append(quick_score_ticker(t, engineered_df, n_trials=n_trials))\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] {t}: {e}\")\n",
    "            rows.append({\"ticker\": t, \"cv_pr_auc\": np.nan, \"n_events\": np.nan,\n",
    "                         \"n_pos\": np.nan, \"base_pr\": np.nan, \"lift\": np.nan})\n",
    "    res = pd.DataFrame(rows).sort_values([\"lift\", \"cv_pr_auc\"], ascending=False)\n",
    "    print(res)\n",
    "    return res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

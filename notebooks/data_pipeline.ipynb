{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51a41f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'code.src'; 'code' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstock_features\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prepare_data_for_ml, apply_kalman_filter_with_lag\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      3\u001b[39m warnings.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'code.src'; 'code' is not a package"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the parent directory (where 'src' folder is located) to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.stock_features import prepare_data_for_ml, apply_kalman_filter_with_lag\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the parameters for your data pipeline\n",
    "tickers_list = ['PG', 'KO', 'PEP', 'WMT', 'COST', '^GSPC']\n",
    "start_date_str = '2010-01-01'\n",
    "end_date_str = '2023-01-01'\n",
    "output_filename = \"consumer_stocks.csv\"\n",
    "\n",
    "# Make the single function call to run the entire pipeline\n",
    "consumer_stocks_df = prepare_data_for_ml(\n",
    "    tickers=tickers_list,\n",
    "    start_date=start_date_str,\n",
    "    end_date=end_date_str,\n",
    "    #output_engineered_csv=f'data/processed/{output_filename}'\n",
    ")\n",
    "\n",
    "# Apply Kalman filter with lag\n",
    "tickers_to_filter = tickers_list\n",
    "lags_to_use = [1, 5, 10]\n",
    "consumer_stocks_df = apply_kalman_filter_with_lag(consumer_stocks_df, tickers_to_filter, lags_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873ffc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3223 entries, 2010-03-16 to 2022-12-30\n",
      "Columns: 308 entries, Close_COST to Kalman_Filtered_Close_^GSPC_lag_10\n",
      "dtypes: float64(302), int64(6)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": [
    "consumer_stocks_df.head(3)\n",
    "consumer_stocks_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FRED data orchestration pipeline...\n",
      "Fetching and processing data for: CPI (CPIAUCSL)\n",
      "Fetching and processing data for: RETAIL_SALES (RSAFS)\n",
      "Fetching and processing data for: PAYEMS (PAYEMS)\n",
      "Fetching and processing data for: REAL_GDP (GDPC1)\n",
      "Fetching and processing data for: UNEMPLOYMENT (UNRATE)\n",
      "Fetching and processing data for: TREASURY_YIELD (DGS10)\n",
      "Fetching and processing data for: FEDERAL_FUNDS_RATE (DFF)\n",
      "Data orchestration complete.\n",
      "\n",
      "--- Final Merged and Cleaned DataFrame ---\n",
      "            CPIAUCSL     RSAFS    PAYEMS      GDPC1  UNRATE  DGS10   DFF\n",
      "date                                                                    \n",
      "1992-01-01     138.3  159177.0  108365.0  10236.435     7.3   6.71  4.09\n",
      "1992-01-02     138.3  159177.0  108365.0  10236.435     7.3   6.78  4.61\n",
      "1992-01-03     138.3  159177.0  108365.0  10236.435     7.3   6.85  4.06\n",
      "1992-01-04     138.3  159177.0  108365.0  10236.435     7.3   6.85  4.06\n",
      "1992-01-05     138.3  159177.0  108365.0  10236.435     7.3   6.85  4.06\n",
      "\n",
      "Final DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12145 entries, 1992-01-01 to 2025-04-01\n",
      "Freq: D\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   CPIAUCSL  12145 non-null  float64\n",
      " 1   RSAFS     12145 non-null  float64\n",
      " 2   PAYEMS    12145 non-null  float64\n",
      " 3   GDPC1     12145 non-null  float64\n",
      " 4   UNRATE    12145 non-null  float64\n",
      " 5   DGS10     12145 non-null  float64\n",
      " 6   DFF       12145 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 759.1 KB\n",
      "None\n",
      "\n",
      "Final DataFrame NaN count:\n",
      "CPIAUCSL    0\n",
      "RSAFS       0\n",
      "PAYEMS      0\n",
      "GDPC1       0\n",
      "UNRATE      0\n",
      "DGS10       0\n",
      "DFF         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.macro_features import FRED_fetch_macro_data, macro_data_orchestrator\n",
    "import pandas as pd\n",
    "\n",
    "FRED_series_ids = {\n",
    "        'CPI': 'CPIAUCSL',\n",
    "        'FEDERAL_FUNDS_RATE': 'DFF',\n",
    "        'TREASURY_YIELD': 'DGS10',\n",
    "        'UNEMPLOYMENT': 'UNRATE',\n",
    "        'REAL_GDP': 'GDPC1',\n",
    "        'RETAIL_SALES': 'RSAFS',\n",
    "        'PAYEMS': 'PAYEMS' \n",
    "    }\n",
    "\n",
    "macro_funcs = { 'CPI', 'FEDERAL_FUNDS_RATE', 'TREASURY_YIELD', \n",
    "                'UNEMPLOYMENT', 'REAL_GDP', 'RETAIL_SALES', 'PAYEMS' }\n",
    "\n",
    "# Specify a start date to test the new functionality\n",
    "#START_DATE = '2010-01-01'\n",
    "\n",
    "# Now you pass the dictionary explicitly as an argument.\n",
    "combined_macro_df = macro_data_orchestrator(\n",
    "    macro_funcs_to_fetch=macro_funcs,\n",
    "    fred_series_ids_dict=FRED_series_ids,\n",
    ")\n",
    "\n",
    "if not combined_macro_df.empty:\n",
    "    print(\"\\n--- Final Merged and Cleaned DataFrame ---\")\n",
    "    print(combined_macro_df.head())\n",
    "    print(\"\\nFinal DataFrame info:\")\n",
    "    print(combined_macro_df.info())\n",
    "    print(\"\\nFinal DataFrame NaN count:\")\n",
    "    print(combined_macro_df.isna().sum())\n",
    "else:\n",
    "    print(\"Orchestrator returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge the two DataFrames on their date index\n",
    "# The how='left' argument keeps all rows from the stock DataFrame.\n",
    "merged_df = pd.merge(\n",
    "    consumer_stocks_df,\n",
    "    combined_macro_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b608345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the merged DataFrame to a CSV file\n",
    "output_file = r'C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\stock_and_macro.csv'\n",
    "merged_df.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321647fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for a more granular news sentiment search\n",
    "# sentiment_symbol = 'WMT'\n",
    "# sentiment_topics = ['retail_and_wholesale'] \n",
    "# # Use the same date range as your stock data for backtesting\n",
    "# sentiment_start_date = '20230101T0000' # YYYYMMDDTHHMM\n",
    "# sentiment_end_date = '20230801T0000'\n",
    "\n",
    "# print(\"\\n--- Fetching More Granular News Sentiment Data ---\")\n",
    "# news_df = fetch_news_sentiment(\n",
    "#     symbol=sentiment_symbol,\n",
    "#     topics=sentiment_topics,\n",
    "#     sort_by='RELEVANCE',\n",
    "#     time_from=sentiment_start_date,\n",
    "#     time_to=sentiment_end_date\n",
    "# )\n",
    "\n",
    "# news_df.info()\n",
    "# print(news_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

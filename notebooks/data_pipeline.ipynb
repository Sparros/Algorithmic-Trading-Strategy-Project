{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca51a41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 1: Building Stock Feature Pipeline ---\n",
      "\n",
      "--- Starting Stock Feature Pipeline ---\n",
      "Fetching data for 6 tickers...\n",
      "Date range: All available history to Current date\n",
      "Fetching full history for PG...\n",
      "Fetching full history for KO...\n",
      "Fetching full history for PEP...\n",
      "Fetching full history for WMT...\n",
      "Fetching full history for COST...\n",
      "Fetching full history for ^GSPC...\n",
      "\n",
      "Final merged DataFrame has 9858 common entries.\n",
      "\n",
      "Discovered stock prefixes: ['COST', 'KO', 'PEP', 'PG', 'WMT', '^GSPC']\n",
      "\n",
      "Processing features for stock prefix: COST\n",
      "\n",
      "Processing features for stock prefix: KO\n",
      "\n",
      "Processing features for stock prefix: PEP\n",
      "\n",
      "Processing features for stock prefix: PG\n",
      "\n",
      "Processing features for stock prefix: WMT\n",
      "\n",
      "Processing features for stock prefix: ^GSPC\n",
      "\n",
      "Applying general features...\n",
      "\n",
      "Dropped 49 rows due to NaN values after feature engineering.\n",
      "\n",
      "--- Data Preparation Complete ---\n",
      "\n",
      "--- Step 2: Applying Kalman Filter ---\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "# Add the parent directory (where 'src' folder is located) to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.stock_features import build_stock_features_orchestrator, apply_kalman_filter_with_lag\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define the parameters for your data pipeline\n",
    "tickers_list = ['PG', 'KO', 'PEP', 'WMT', 'COST', '^GSPC']\n",
    "start_date_str = '2010-01-01'\n",
    "end_date_str = '2023-01-01'\n",
    "output_filename = \"stock_and_macro.csv\"\n",
    "\n",
    "# Define the new parameters for the stock feature pipeline\n",
    "target_ticker = 'WMT'\n",
    "supplier_tickers = ['KO', 'PEP']\n",
    "benchmark_ticker = '^GSPC'\n",
    "\n",
    "# 1. Build the stock feature pipeline\n",
    "print(\"\\n--- Step 1: Building Stock Feature Pipeline ---\")\n",
    "consumer_stocks_df = build_stock_features_orchestrator(\n",
    "    tickers=tickers_list,\n",
    "    target_ticker=target_ticker,\n",
    "    supplier_tickers=supplier_tickers,\n",
    "    benchmark_ticker=benchmark_ticker,\n",
    "    #start_date=start_date_str,\n",
    "    #end_date=end_date_str,\n",
    ")\n",
    "\n",
    "# 2. Apply Kalman filter with lag on the output\n",
    "print(\"\\n--- Step 2: Applying Kalman Filter ---\")\n",
    "tickers_to_filter = tickers_list\n",
    "lags_to_use = [1, 5, 10]\n",
    "consumer_stocks_df = apply_kalman_filter_with_lag(consumer_stocks_df, tickers_to_filter, lags_to_use)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf3108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FRED data orchestration pipeline...\n",
      "Fetching and processing data for: UNEMPLOYMENT (UNRATE)\n",
      "Fetching and processing data for: CPI (CPIAUCSL)\n",
      "Fetching and processing data for: PAYEMS (PAYEMS)\n",
      "Fetching and processing data for: RETAIL_SALES (RSAFS)\n",
      "Fetching and processing data for: TREASURY_YIELD (DGS10)\n",
      "Fetching and processing data for: REAL_GDP (GDPC1)\n",
      "Fetching and processing data for: FEDERAL_FUNDS_RATE (DFF)\n",
      "Data orchestration complete.\n",
      "\n",
      "--- Final Merged and Cleaned DataFrame ---\n",
      "            UNRATE  CPIAUCSL    PAYEMS     RSAFS  DGS10      GDPC1   DFF\n",
      "date                                                                    \n",
      "1992-01-01     7.3     138.3  108365.0  159177.0   6.71  10236.435  4.09\n",
      "1992-01-02     7.3     138.3  108365.0  159177.0   6.78  10236.435  4.61\n",
      "1992-01-03     7.3     138.3  108365.0  159177.0   6.85  10236.435  4.06\n",
      "1992-01-04     7.3     138.3  108365.0  159177.0   6.85  10236.435  4.06\n",
      "1992-01-05     7.3     138.3  108365.0  159177.0   6.85  10236.435  4.06\n",
      "\n",
      "Final DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 12145 entries, 1992-01-01 to 2025-04-01\n",
      "Freq: D\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   UNRATE    12145 non-null  float64\n",
      " 1   CPIAUCSL  12145 non-null  float64\n",
      " 2   PAYEMS    12145 non-null  float64\n",
      " 3   RSAFS     12145 non-null  float64\n",
      " 4   DGS10     12145 non-null  float64\n",
      " 5   GDPC1     12145 non-null  float64\n",
      " 6   DFF       12145 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 759.1 KB\n",
      "None\n",
      "\n",
      "Final DataFrame NaN count:\n",
      "UNRATE      0\n",
      "CPIAUCSL    0\n",
      "PAYEMS      0\n",
      "RSAFS       0\n",
      "DGS10       0\n",
      "GDPC1       0\n",
      "DFF         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from src.macro_features import macro_data_orchestrator\n",
    "\n",
    "FRED_series_ids = {\n",
    "        'CPI': 'CPIAUCSL',\n",
    "        'FEDERAL_FUNDS_RATE': 'DFF',\n",
    "        'TREASURY_YIELD': 'DGS10',\n",
    "        'UNEMPLOYMENT': 'UNRATE',\n",
    "        'REAL_GDP': 'GDPC1',\n",
    "        'RETAIL_SALES': 'RSAFS',\n",
    "        'PAYEMS': 'PAYEMS' \n",
    "    }\n",
    "\n",
    "macro_funcs = { 'CPI', 'FEDERAL_FUNDS_RATE', 'TREASURY_YIELD', \n",
    "                'UNEMPLOYMENT', 'REAL_GDP', 'RETAIL_SALES', 'PAYEMS' }\n",
    "\n",
    "\n",
    "# Now you pass the dictionary explicitly as an argument.\n",
    "combined_macro_df = macro_data_orchestrator(\n",
    "    macro_funcs_to_fetch=macro_funcs,\n",
    "    fred_series_ids_dict=FRED_series_ids,\n",
    ")\n",
    "\n",
    "if not combined_macro_df.empty:\n",
    "    print(\"\\n--- Final Merged and Cleaned DataFrame ---\")\n",
    "    print(combined_macro_df.head())\n",
    "    print(\"\\nFinal DataFrame info:\")\n",
    "    print(combined_macro_df.info())\n",
    "    print(\"\\nFinal DataFrame NaN count:\")\n",
    "    print(combined_macro_df.isna().sum())\n",
    "else:\n",
    "    print(\"Orchestrator returned an empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acf0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9809 entries, 1986-09-17 to 2025-08-22\n",
      "Columns: 292 entries, Open_PG to DFF\n",
      "dtypes: float64(291), int64(1)\n",
      "memory usage: 21.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3. Merge the two DataFrames on their date index\n",
    "# The how='left' argument keeps all rows from the stock DataFrame.\n",
    "\n",
    "# Correct the time zone issue by making the stock index timezone-naive\n",
    "# This aligns it with the macro data's index\n",
    "consumer_stocks_df.index = consumer_stocks_df.index.tz_localize(None)\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    consumer_stocks_df,\n",
    "    combined_macro_df,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Now, let's inspect the merged DataFrame\n",
    "print(merged_df.info())\n",
    "#print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b608345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the merged DataFrame to a CSV file\n",
    "output_file = r'C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\consumer_staples_data.csv'\n",
    "merged_df.to_csv(output_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321647fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d93bc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add parent directory to path to access custom modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.modelling_functions import create_target_variable, check_feature_stability, detect_market_regimes, regime_aware_validation, calculate_sharpe_with_costs, calculate_max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fc6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "CONFIG = {\n",
    "    'data_path': r'C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\consumer_staples_data.csv',\n",
    "    'model_dir': r\"C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\models\",\n",
    "    'window': 5,\n",
    "    'threshold': 0.005,\n",
    "    'target_ticker': 'WMT',\n",
    "    'train_end': '2020-12-31',\n",
    "    'val_end': '2021-12-31',\n",
    "    'test_start': '2022-01-01',\n",
    "    'n_trials': 100,\n",
    "    'transaction_cost': 0.001,  # 0.1% per trade\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1710747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully: (9809, 292)\n",
      "\n",
      "--- Data Setup ---\n",
      "Window: 5, Threshold: 0.005\n",
      "Features: 285, Samples: 8372\n",
      "Class imbalance ratio (0/1): 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\epoch_bpjmdqk\\AppData\\Local\\Temp\\ipykernel_12168\\2980044324.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. DATA PREPARATION ---\n",
    "try:\n",
    "    data = pd.read_csv(CONFIG['data_path'], index_col='Date', parse_dates=True)\n",
    "    print(f\"✅ Data loaded successfully: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Data file not found at {CONFIG['data_path']}\")\n",
    "    sys.exit()\n",
    "\n",
    "# Create target variable\n",
    "data_target = create_target_variable(data.copy(), CONFIG['target_ticker'], \n",
    "                                   window=CONFIG['window'], threshold=CONFIG['threshold'])\n",
    "target_return_col = f\"{CONFIG['target_ticker']}_target_return_{CONFIG['window']}D_{CONFIG['threshold']}\"\n",
    "\n",
    "# Define features (exclude target-related columns)\n",
    "exclude_cols = [\n",
    "    f\"{CONFIG['target_ticker']}_Target\",\n",
    "    target_return_col,\n",
    "    f\"Open_{CONFIG['target_ticker']}\",\n",
    "    f\"High_{CONFIG['target_ticker']}\",\n",
    "    f\"Low_{CONFIG['target_ticker']}\",\n",
    "    f\"Close_{CONFIG['target_ticker']}\",\n",
    "    f\"Volume_{CONFIG['target_ticker']}\",\n",
    "    f\"Dividends_{CONFIG['target_ticker']}\",\n",
    "    f\"Stock Splits_{CONFIG['target_ticker']}\"\n",
    "]\n",
    "\n",
    "features = [col for col in data_target.columns if col not in exclude_cols]\n",
    "data_target.dropna(inplace=True)\n",
    "\n",
    "X_features = data_target[features]\n",
    "y = data_target[f\"{CONFIG['target_ticker']}_Target\"]\n",
    "returns_full = data_target[target_return_col]\n",
    "\n",
    "# Clean data\n",
    "X_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_features = X_features.fillna(X_features.mean()).fillna(0)\n",
    "\n",
    "# Calculate class imbalance\n",
    "neg_to_pos_ratio = (y == 0).sum() / (y == 1).sum()\n",
    "\n",
    "print(f\"\\n--- Data Setup ---\")\n",
    "print(f\"Window: {CONFIG['window']}, Threshold: {CONFIG['threshold']}\")\n",
    "print(f\"Features: {len(features)}, Samples: {len(X_features)}\")\n",
    "print(f\"Class imbalance ratio (0/1): {neg_to_pos_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9fcc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Time Series Split ---\n",
      "Train: 7306 samples (1992-01-02 00:00:00 to 2020-12-31 00:00:00)\n",
      "Val:   252 samples (2021-01-04 00:00:00 to 2021-12-31 00:00:00)\n",
      "Test:  814 samples (2022-01-03 00:00:00 to 2025-04-01 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "# --- 2. THREE-WAY TIME SERIES SPLIT ---\n",
    "print(f\"\\n--- Time Series Split ---\")\n",
    "train_mask = X_features.index <= CONFIG['train_end']\n",
    "val_mask = (X_features.index > CONFIG['train_end']) & (X_features.index <= CONFIG['val_end'])\n",
    "test_mask = X_features.index > CONFIG['val_end']\n",
    "\n",
    "X_train = X_features[train_mask]\n",
    "X_val = X_features[val_mask] \n",
    "X_test = X_features[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_val = y[val_mask]\n",
    "y_test = y[test_mask]\n",
    "returns_train = returns_full[train_mask]\n",
    "returns_val = returns_full[val_mask]\n",
    "returns_test = returns_full[test_mask]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples ({X_train.index.min()} to {X_train.index.max()})\")\n",
    "print(f\"Val:   {len(X_val)} samples ({X_val.index.min()} to {X_val.index.max()})\")\n",
    "print(f\"Test:  {len(X_test)} samples ({X_test.index.min()} to {X_test.index.max()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c546eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Stability Analysis ---\n",
      "Most stable features (CV < 0.5):\n",
      "  Open_^GSPC: CV = 0.123\n",
      "\n",
      "Using 1 most stable features for modeling\n"
     ]
    }
   ],
   "source": [
    "# --- 3. FEATURE STABILITY ANALYSIS ---\n",
    "stable_features = check_feature_stability(X_train, y_train, X_train.columns, CONFIG['random_state'])\n",
    "print(f\"\\nUsing {len(stable_features)} most stable features for modeling\")\n",
    "\n",
    "# Filter to stable features\n",
    "X_train_stable = X_train[stable_features]\n",
    "X_val_stable = X_val[stable_features]\n",
    "X_test_stable = X_test[stable_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb44c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Market regimes detected:\n",
      "0.0    2089\n",
      "1.0    3436\n",
      "2.0    2847\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 4. REGIME DETECTION ---\n",
    "market_returns = returns_full  # Or use market index if available\n",
    "regimes = detect_market_regimes(market_returns)\n",
    "print(f\"\\nMarket regimes detected:\")\n",
    "print(regimes.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f2ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-29 17:31:22,322] A new study created in memory with name: no-name-6219e6e9-aa18-458c-b447-ace441e87f7b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Optuna Optimization ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09c6882c9534ef29cf8be70b5900106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-08-29 17:31:22,336] Trial 0 failed with parameters: {'n_estimators': 362, 'learning_rate': 0.17254716573280354, 'max_depth': 7, 'subsample': 0.8795975452591109, 'colsample_bytree': 0.7468055921327309, 'gamma': 0.7799726016810132} because of the following error: ValueError('The `low` value must be smaller than or equal to the `high` value (low=2, high=0).').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\epoch_bpjmdqk\\AppData\\Local\\Temp\\ipykernel_12168\\3573687207.py\", line 21, in enhanced_objective\n",
      "    pca_components = trial.suggest_int('pca_n_components', 2, max_pca_components)\n",
      "  File \"c:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\_convert_positional_args.py\", line 135, in converter_wrapper\n",
      "    return func(**kwargs)  # type: ignore[call-arg]\n",
      "  File \"c:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\trial\\_trial.py\", line 327, in suggest_int\n",
      "    distribution = IntDistribution(low=low, high=high, log=log, step=step)\n",
      "  File \"c:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\distributions.py\", line 356, in __init__\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: The `low` value must be smaller than or equal to the `high` value (low=2, high=0).\n",
      "[W 2025-08-29 17:31:22,341] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The `low` value must be smaller than or equal to the `high` value (low=2, high=0).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# Run Optuna study\u001b[39;00m\n\u001b[32m     82\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     83\u001b[39m                           sampler=optuna.samplers.TPESampler(seed=CONFIG[\u001b[33m'\u001b[39m\u001b[33mrandom_state\u001b[39m\u001b[33m'\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_trials\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Optimization Results ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest Sharpe ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36menhanced_objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Tunable pipeline components - limit PCA to available features\u001b[39;00m\n\u001b[32m     20\u001b[39m max_pca_components = \u001b[38;5;28mmin\u001b[39m(\u001b[32m10\u001b[39m, \u001b[38;5;28mlen\u001b[39m(stable_features) - \u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m)  \u001b[38;5;66;03m# Conservative limit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m pca_components = \u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuggest_int\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpca_n_components\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_pca_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m selector_threshold = trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mselector_threshold\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m0.75*mean\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     24\u001b[39m model = XGBClassifier(**params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\_convert_positional_args.py:135\u001b[39m, in \u001b[36mconvert_positional_args.<locals>.converter_decorator.<locals>.converter_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() got multiple values for arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduplicated_kwds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m     )\n\u001b[32m    133\u001b[39m kwargs.update(inferred_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\trial\\_trial.py:327\u001b[39m, in \u001b[36mTrial.suggest_int\u001b[39m\u001b[34m(self, name, low, high, step, log)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;129m@convert_positional_args\u001b[39m(\n\u001b[32m    239\u001b[39m     previous_positional_arg_names=_SUGGEST_INT_POSITIONAL_ARGS,\n\u001b[32m    240\u001b[39m     deprecated_version=\u001b[33m\"\u001b[39m\u001b[33m3.5.0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m     \u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, low: \u001b[38;5;28mint\u001b[39m, high: \u001b[38;5;28mint\u001b[39m, *, step: \u001b[38;5;28mint\u001b[39m = \u001b[32m1\u001b[39m, log: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    245\u001b[39m ) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m    246\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Suggest a value for the integer parameter.\u001b[39;00m\n\u001b[32m    247\u001b[39m \n\u001b[32m    248\u001b[39m \u001b[33;03m    The value is sampled from the integers in :math:`[\\\\mathsf{low}, \\\\mathsf{high}]`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    324\u001b[39m \u001b[33;03m        :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[32m    325\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     distribution = \u001b[43mIntDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     suggested_value = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m._suggest(name, distribution))\n\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_distribution(name, distribution)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\epoch_bpjmdqk\\Documents\\Code\\venv\\Lib\\site-packages\\optuna\\distributions.py:356\u001b[39m, in \u001b[36mIntDistribution.__init__\u001b[39m\u001b[34m(self, low, high, log, step)\u001b[39m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSamplers and other components in Optuna only accept step is 1 \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwhen `log` argument is True.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    353\u001b[39m     )\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m low > high:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    357\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `low` value must be smaller than or equal to the `high` value \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(low=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, high=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m.format(low, high)\n\u001b[32m    359\u001b[39m     )\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log \u001b[38;5;129;01mand\u001b[39;00m low < \u001b[32m1\u001b[39m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    363\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `low` value must be equal to or greater than 1 for a log distribution \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(low=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, high=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m.format(low, high)\n\u001b[32m    365\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: The `low` value must be smaller than or equal to the `high` value (low=2, high=0)."
     ]
    }
   ],
   "source": [
    "# --- 5. ENHANCED OPTUNA OPTIMIZATION ---\n",
    "def enhanced_objective(trial):\n",
    "    # Expanded search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'scale_pos_weight': neg_to_pos_ratio,\n",
    "        'early_stopping_rounds': 20,  # Move to model params\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': CONFIG['random_state'],\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    # Tunable pipeline components - limit PCA to available features\n",
    "    max_pca_components = min(10, len(stable_features) - 1, 50)  # Conservative limit\n",
    "    pca_components = trial.suggest_int('pca_n_components', 2, max_pca_components)\n",
    "    selector_threshold = trial.suggest_categorical('selector_threshold', ['mean', 'median', '0.75*mean'])\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    selector = SelectFromModel(model, threshold=selector_threshold)\n",
    "    \n",
    "    # Time series cross-validation on training data only\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    sharpe_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(X_train_stable):\n",
    "        X_cv_train = X_train_stable.iloc[train_idx]\n",
    "        X_cv_val = X_train_stable.iloc[val_idx]\n",
    "        y_cv_train = y_train.iloc[train_idx]\n",
    "        y_cv_val = y_train.iloc[val_idx]\n",
    "        returns_cv_val = returns_train.iloc[val_idx]\n",
    "        \n",
    "        try:\n",
    "            # Fit feature selection and scaling first\n",
    "            scaler = StandardScaler()\n",
    "            X_cv_train_scaled = scaler.fit_transform(X_cv_train)\n",
    "            X_cv_val_scaled = scaler.transform(X_cv_val)\n",
    "            \n",
    "            # Feature selection\n",
    "            selector_temp = SelectFromModel(XGBClassifier(n_estimators=50, random_state=42), \n",
    "                                          threshold=selector_threshold)\n",
    "            X_cv_train_selected = selector_temp.fit_transform(X_cv_train_scaled, y_cv_train)\n",
    "            X_cv_val_selected = selector_temp.transform(X_cv_val_scaled)\n",
    "            \n",
    "            # Skip if too few features selected\n",
    "            if X_cv_train_selected.shape[1] < 2:\n",
    "                continue\n",
    "                \n",
    "            # PCA - adjust components if needed\n",
    "            actual_pca_components = min(pca_components, X_cv_train_selected.shape[1])\n",
    "            pca = PCA(n_components=actual_pca_components)\n",
    "            X_cv_train_pca = pca.fit_transform(X_cv_train_selected)\n",
    "            X_cv_val_pca = pca.transform(X_cv_val_selected)\n",
    "            \n",
    "            # Train final model with early stopping\n",
    "            model_temp = XGBClassifier(**{k: v for k, v in params.items() \n",
    "                                        if k not in ['early_stopping_rounds']})\n",
    "            model_temp.fit(X_cv_train_pca, y_cv_train,\n",
    "                          early_stopping_rounds=20,\n",
    "                          eval_set=[(X_cv_val_pca, y_cv_val)],\n",
    "                          verbose=False)\n",
    "            \n",
    "            preds = model_temp.predict(X_cv_val_pca)\n",
    "            strategy_returns = preds * returns_cv_val\n",
    "            sharpe = calculate_sharpe_with_costs(strategy_returns, CONFIG['transaction_cost'])\n",
    "            sharpe_scores.append(sharpe if not np.isnan(sharpe) and np.isfinite(sharpe) else -1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Silently skip failed trials during optimization\n",
    "            continue\n",
    "    \n",
    "    return np.mean(sharpe_scores) if sharpe_scores else -10\n",
    "\n",
    "print(\"\\n--- Starting Optuna Optimization ---\")\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction='maximize', \n",
    "                          sampler=optuna.samplers.TPESampler(seed=CONFIG['random_state']))\n",
    "study.optimize(enhanced_objective, n_trials=CONFIG['n_trials'], show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n--- Optimization Results ---\")\n",
    "print(f\"Best Sharpe ratio: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "# Extract pipeline parameters\n",
    "pca_components = best_params.pop('pca_n_components')\n",
    "selector_threshold = best_params.pop('selector_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ede061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. TRAIN FINAL MODEL ---\n",
    "print(\"\\n--- Training Final Model ---\")\n",
    "\n",
    "# Extract best parameters and remove non-XGBoost params\n",
    "final_model_params = {k: v for k, v in best_params.items() \n",
    "                      if k not in ['pca_n_components', 'selector_threshold']}\n",
    "final_model_params.update({\n",
    "    'scale_pos_weight': neg_to_pos_ratio,\n",
    "    'early_stopping_rounds': 20,\n",
    "    'eval_metric': 'logloss', \n",
    "    'random_state': CONFIG['random_state'],\n",
    "    'n_jobs': -1,\n",
    "    'tree_method': 'hist'\n",
    "})\n",
    "\n",
    "# Build pipeline step by step for better control\n",
    "scaler = StandardScaler()\n",
    "temp_model = XGBClassifier(n_estimators=50, random_state=42)  # Quick model for feature selection\n",
    "selector = SelectFromModel(temp_model, threshold=selector_threshold)\n",
    "\n",
    "# Fit preprocessing steps\n",
    "X_train_scaled = scaler.fit_transform(X_train_stable)\n",
    "X_val_scaled = scaler.transform(X_val_stable)\n",
    "\n",
    "# Feature selection\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_val_selected = selector.transform(X_val_scaled)\n",
    "\n",
    "print(f\"Features after selection: {X_train_selected.shape[1]}\")\n",
    "\n",
    "# PCA with dynamic component adjustment\n",
    "actual_pca_components = min(pca_components, X_train_selected.shape[1])\n",
    "pca = PCA(n_components=actual_pca_components)\n",
    "X_train_pca = pca.fit_transform(X_train_selected)\n",
    "X_val_pca = pca.transform(X_val_selected)\n",
    "\n",
    "print(f\"PCA components used: {actual_pca_components}\")\n",
    "\n",
    "# Train final model with early stopping\n",
    "final_model = XGBClassifier(**final_model_params)\n",
    "final_model.fit(X_train_pca, y_train,\n",
    "               early_stopping_rounds=20,\n",
    "               eval_set=[(X_val_pca, y_val)],\n",
    "               verbose=True)\n",
    "\n",
    "# Create complete pipeline for saving\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('feature_select', selector), \n",
    "    ('pca', pca),\n",
    "    ('model', final_model)\n",
    "])\n",
    "\n",
    "print(\"✅ Final model trained with early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. COMPREHENSIVE MODEL EVALUATION ---\n",
    "def evaluate_model_comprehensive(scaler, selector, pca_model, model, X_test, y_test, returns_test, regimes_test, set_name=\"Test\"):\n",
    "    \"\"\"Comprehensive model evaluation with manual pipeline\"\"\"\n",
    "    print(f\"\\n--- {set_name} Set Evaluation ---\")\n",
    "    \n",
    "    # Manual pipeline prediction\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "    X_test_pca = pca_model.transform(X_test_selected)\n",
    "    \n",
    "    # Basic predictions\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    y_pred_proba = model.predict_proba(X_test_pca)[:, 1]\n",
    "    \n",
    "    # Strategy returns\n",
    "    strategy_returns = y_pred * returns_test\n",
    "    \n",
    "    # Performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sharpe = calculate_sharpe_with_costs(strategy_returns, CONFIG['transaction_cost'])\n",
    "    max_dd = calculate_max_drawdown(strategy_returns.cumsum())\n",
    "    total_return = strategy_returns.sum()\n",
    "    \n",
    "    # Win rate and trade statistics\n",
    "    winning_trades = strategy_returns[strategy_returns > 0]\n",
    "    losing_trades = strategy_returns[strategy_returns < 0]\n",
    "    win_rate = len(winning_trades) / len(strategy_returns[strategy_returns != 0]) if len(strategy_returns[strategy_returns != 0]) > 0 else 0\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Sharpe Ratio (w/ costs): {sharpe:.4f}\")\n",
    "    print(f\"Total Return: {total_return:.4f}\")\n",
    "    print(f\"Max Drawdown: {max_dd:.4f}\")\n",
    "    print(f\"Win Rate: {win_rate:.4f}\")\n",
    "    print(f\"Avg Winning Trade: {winning_trades.mean():.6f}\")\n",
    "    print(f\"Avg Losing Trade: {losing_trades.mean():.6f}\")\n",
    "    print(f\"Number of Trades: {(y_pred != 0).sum()}\")\n",
    "    \n",
    "    # Regime-specific performance\n",
    "    if regimes_test is not None and len(regimes_test) > 0:\n",
    "        print(f\"\\nRegime Performance:\")\n",
    "        for regime in regimes_test.unique():\n",
    "            regime_mask = regimes_test == regime\n",
    "            if regime_mask.sum() > 10:\n",
    "                regime_returns = strategy_returns[regime_mask]\n",
    "                regime_sharpe = calculate_sharpe_with_costs(regime_returns, CONFIG['transaction_cost'])\n",
    "                regime_names = {0: 'Low Vol', 1: 'Normal Vol', 2: 'High Vol'}\n",
    "                print(f\"  {regime_names.get(regime, f'Regime {regime}')}: Sharpe = {regime_sharpe:.3f} ({regime_mask.sum()} samples)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'sharpe': sharpe,\n",
    "        'total_return': total_return,\n",
    "        'max_drawdown': max_dd,\n",
    "        'win_rate': win_rate,\n",
    "        'n_trades': (y_pred != 0).sum()\n",
    "    }\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_regimes = regimes[val_mask] if len(regimes[val_mask]) > 0 else None\n",
    "val_results = evaluate_model_comprehensive(scaler, selector, pca, final_model, X_val_stable, y_val, \n",
    "                                         returns_val, val_regimes, \"Validation\")\n",
    "\n",
    "# Evaluate on test set (final, unbiased evaluation)\n",
    "test_regimes = regimes[test_mask] if len(regimes[test_mask]) > 0 else None\n",
    "test_results = evaluate_model_comprehensive(scaler, selector, pca, final_model, X_test_stable, y_test, \n",
    "                                          returns_test, test_regimes, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec892a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. ROBUST PERMUTATION IMPORTANCE ---\n",
    "print(\"\\n--- Permutation Importance Analysis ---\")\n",
    "\n",
    "# Get selected features from the fitted selector\n",
    "selected_features = X_train_stable.columns[selector.get_support()]\n",
    "print(f\"Selected {len(selected_features)} features for importance analysis\")\n",
    "\n",
    "# Use only training data for feature importance to avoid bias\n",
    "# Note: We use the original selected features, not PCA components\n",
    "X_train_for_pi = X_train_stable[selected_features]\n",
    "pi_result = permutation_importance(\n",
    "    lambda X: final_model.predict(pca.transform(selector.transform(scaler.transform(X)))),\n",
    "    X_train_for_pi, y_train, \n",
    "    n_repeats=10, random_state=CONFIG['random_state'], n_jobs=-1,\n",
    "    scoring='accuracy'  # Use accuracy since we need a scorer function\n",
    ")\n",
    "\n",
    "sorted_idx = pi_result.importances_mean.argsort()[::-1]\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "for i in sorted_idx[:10]:\n",
    "    if i < len(selected_features):\n",
    "        feature_name = selected_features[i]\n",
    "        importance_mean = pi_result.importances_mean[i]\n",
    "        importance_std = pi_result.importances_std[i]\n",
    "        print(f\"  {feature_name}: {importance_mean:.4f} ± {importance_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. OVERFITTING CHECKS ---\n",
    "print(\"\\n--- Overfitting Analysis ---\")\n",
    "\n",
    "# Compare train vs validation performance using manual pipeline\n",
    "X_train_scaled_eval = scaler.transform(X_train_stable)\n",
    "X_train_selected_eval = selector.transform(X_train_scaled_eval)\n",
    "X_train_pca_eval = pca.transform(X_train_selected_eval)\n",
    "train_pred = final_model.predict(X_train_pca_eval)\n",
    "train_strategy_returns = train_pred * returns_train\n",
    "train_sharpe = calculate_sharpe_with_costs(train_strategy_returns, CONFIG['transaction_cost'])\n",
    "\n",
    "print(f\"Training Sharpe: {train_sharpe:.4f}\")\n",
    "print(f\"Validation Sharpe: {val_results['sharpe']:.4f}\")\n",
    "print(f\"Test Sharpe: {test_results['sharpe']:.4f}\")\n",
    "\n",
    "sharpe_degradation = (train_sharpe - test_results['sharpe']) / abs(train_sharpe) if train_sharpe != 0 else 0\n",
    "print(f\"Sharpe degradation (train→test): {sharpe_degradation:.2%}\")\n",
    "\n",
    "if sharpe_degradation > 0.5:\n",
    "    print(\"Warning: Significant performance degradation detected. Model may be overfitting.\")\n",
    "elif sharpe_degradation > 0.2:\n",
    "    print(\"Caution: Moderate performance degradation. Monitor in backtesting.\")\n",
    "else:\n",
    "    print(\"Performance degradation within acceptable limits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. MODEL PERSISTENCE ---\n",
    "os.makedirs(CONFIG['model_dir'], exist_ok=True)\n",
    "\n",
    "# Save the final pipeline\n",
    "model_filename = os.path.join(CONFIG['model_dir'], \"final_xgb_optuna_pipeline_enhanced.pkl\")\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'config': CONFIG,\n",
    "    'best_params': {**final_model_params, 'pca_n_components': actual_pca_components, 'selector_threshold': selector_threshold},\n",
    "    'class_imbalance_ratio': neg_to_pos_ratio,\n",
    "    'selected_features': list(selected_features),\n",
    "    'stable_features': stable_features,\n",
    "    'validation_results': val_results,\n",
    "    'test_results': test_results,\n",
    "    'train_sharpe': train_sharpe,\n",
    "    'feature_importance': {\n",
    "        feature: float(importance) \n",
    "        for i, (feature, importance) in enumerate(zip(selected_features[sorted_idx[:20]], \n",
    "                                     pi_result.importances_mean[sorted_idx[:20]]))\n",
    "        if i < len(selected_features)\n",
    "    },\n",
    "    'training_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "metadata_filename = os.path.join(CONFIG['model_dir'], \"model_metadata_enhanced.json\")\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✅ Enhanced pipeline saved as '{model_filename}'\")\n",
    "print(f\"✅ Model metadata saved as '{metadata_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485aa691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. REGIME-AWARE FINAL VALIDATION ---\n",
    "if len(regimes) > 0:\n",
    "    print(\"\\n--- Final Regime Analysis ---\")\n",
    "    regime_performance = regime_aware_validation(X_test_stable, y_test, returns_test, test_regimes, final_pipeline)\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"Final Test Sharpe Ratio: {test_results['sharpe']:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(f\"Model ready for backtesting phase.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249f71c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'regimes_aware_validation' from 'src.modelling_functions' (c:\\Users\\epoch_bpjmdqk\\Documents\\Code\\src\\modelling_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Add parent directory to path to access custom modules\u001b[39;00m\n\u001b[32m     15\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodelling_functions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_target_variable, check_feature_stability, detect_market_regimes, regimes_aware_validation, calculate_sharpe_with_costs\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'regimes_aware_validation' from 'src.modelling_functions' (c:\\Users\\epoch_bpjmdqk\\Documents\\Code\\src\\modelling_functions.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add parent directory to path to access custom modules\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.modelling_functions import create_target_variable, check_feature_stability, detect_market_regimes, regime_aware_validation, calculate_sharpe_with_costs, calculate_max_drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "CONFIG = {\n",
    "    'data_path': r'C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\data\\processed\\consumer_staples_data.csv',\n",
    "    'model_dir': r\"C:\\Users\\epoch_bpjmdqk\\Documents\\Code\\models\",\n",
    "    'window': 5,\n",
    "    'threshold': 0.005,\n",
    "    'target_ticker': 'WMT',\n",
    "    'train_end': '2020-12-31',\n",
    "    'val_end': '2021-12-31',\n",
    "    'test_start': '2022-01-01',\n",
    "    'n_trials': 100,\n",
    "    'transaction_cost': 0.001,  # 0.1% per trade\n",
    "    'random_state': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9801717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DATA PREPARATION ---\n",
    "try:\n",
    "    data = pd.read_csv(CONFIG['data_path'], index_col='Date', parse_dates=True)\n",
    "    print(f\"✅ Data loaded successfully: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Data file not found at {CONFIG['data_path']}\")\n",
    "    sys.exit()\n",
    "\n",
    "# Create target variable\n",
    "data_target = create_target_variable(data.copy(), CONFIG['target_ticker'], \n",
    "                                   window=CONFIG['window'], threshold=CONFIG['threshold'])\n",
    "target_return_col = f\"{CONFIG['target_ticker']}_target_return_{CONFIG['window']}D_{CONFIG['threshold']}\"\n",
    "\n",
    "# Define features (exclude target-related columns)\n",
    "exclude_cols = [\n",
    "    f\"{CONFIG['target_ticker']}_Target\",\n",
    "    target_return_col,\n",
    "    f\"Open_{CONFIG['target_ticker']}\",\n",
    "    f\"High_{CONFIG['target_ticker']}\",\n",
    "    f\"Low_{CONFIG['target_ticker']}\",\n",
    "    f\"Close_{CONFIG['target_ticker']}\",\n",
    "    f\"Volume_{CONFIG['target_ticker']}\",\n",
    "    f\"Dividends_{CONFIG['target_ticker']}\",\n",
    "    f\"Stock Splits_{CONFIG['target_ticker']}\"\n",
    "]\n",
    "\n",
    "features = [col for col in data_target.columns if col not in exclude_cols]\n",
    "data_target.dropna(inplace=True)\n",
    "\n",
    "X_features = data_target[features]\n",
    "y = data_target[f\"{CONFIG['target_ticker']}_Target\"]\n",
    "returns_full = data_target[target_return_col]\n",
    "\n",
    "# Clean data\n",
    "X_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_features = X_features.fillna(X_features.mean()).fillna(0)\n",
    "\n",
    "# Calculate class imbalance\n",
    "neg_to_pos_ratio = (y == 0).sum() / (y == 1).sum()\n",
    "\n",
    "print(f\"\\n--- Data Setup ---\")\n",
    "print(f\"Window: {CONFIG['window']}, Threshold: {CONFIG['threshold']}\")\n",
    "print(f\"Features: {len(features)}, Samples: {len(X_features)}\")\n",
    "print(f\"Class imbalance ratio (0/1): {neg_to_pos_ratio:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. THREE-WAY TIME SERIES SPLIT ---\n",
    "print(f\"\\n--- Time Series Split ---\")\n",
    "train_mask = X_features.index <= CONFIG['train_end']\n",
    "val_mask = (X_features.index > CONFIG['train_end']) & (X_features.index <= CONFIG['val_end'])\n",
    "test_mask = X_features.index > CONFIG['val_end']\n",
    "\n",
    "X_train = X_features[train_mask]\n",
    "X_val = X_features[val_mask] \n",
    "X_test = X_features[test_mask]\n",
    "y_train = y[train_mask]\n",
    "y_val = y[val_mask]\n",
    "y_test = y[test_mask]\n",
    "returns_train = returns_full[train_mask]\n",
    "returns_val = returns_full[val_mask]\n",
    "returns_test = returns_full[test_mask]\n",
    "\n",
    "print(f\"Train: {len(X_train)} samples ({X_train.index.min()} to {X_train.index.max()})\")\n",
    "print(f\"Val:   {len(X_val)} samples ({X_val.index.min()} to {X_val.index.max()})\")\n",
    "print(f\"Test:  {len(X_test)} samples ({X_test.index.min()} to {X_test.index.max()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ac55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. FEATURE STABILITY ANALYSIS ---\n",
    "stable_features = check_feature_stability(X_train, y_train, X_train.columns, CONFIG['random_state'])\n",
    "print(f\"\\nUsing {len(stable_features)} most stable features for modeling\")\n",
    "\n",
    "# Filter to stable features\n",
    "X_train_stable = X_train[stable_features]\n",
    "X_val_stable = X_val[stable_features]\n",
    "X_test_stable = X_test[stable_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. REGIME DETECTION ---\n",
    "market_returns = returns_full  # Or use market index if available\n",
    "regimes = detect_market_regimes(market_returns)\n",
    "print(f\"\\nMarket regimes detected:\")\n",
    "print(regimes.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. ENHANCED OPTUNA OPTIMIZATION ---\n",
    "def enhanced_objective(trial):\n",
    "    # Expanded search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 800),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'scale_pos_weight': neg_to_pos_ratio,\n",
    "        'eval_metric': 'logloss',\n",
    "        'random_state': CONFIG['random_state'],\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "    \n",
    "    # Tunable pipeline components\n",
    "    pca_components = trial.suggest_int('pca_n_components', 2, min(10, len(stable_features)))\n",
    "    selector_threshold = trial.suggest_categorical('selector_threshold', ['mean', 'median', '0.75*mean'])\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "    selector = SelectFromModel(model, threshold=selector_threshold)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', selector),\n",
    "        ('pca', PCA(n_components=pca_components)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Time series cross-validation on training data only\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    sharpe_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in tscv.split(X_train_stable):\n",
    "        X_cv_train = X_train_stable.iloc[train_idx]\n",
    "        X_cv_val = X_train_stable.iloc[val_idx]\n",
    "        y_cv_train = y_train.iloc[train_idx]\n",
    "        y_cv_val = y_train.iloc[val_idx]\n",
    "        returns_cv_val = returns_train.iloc[val_idx]\n",
    "        \n",
    "        # Early stopping on CV validation set\n",
    "        fit_params = {\n",
    "            \"model__early_stopping_rounds\": 20,\n",
    "            \"model__eval_set\": [(X_cv_val, y_cv_val)],\n",
    "            \"model__verbose\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            pipeline.fit(X_cv_train, y_cv_train, **fit_params)\n",
    "            preds = pipeline.predict(X_cv_val)\n",
    "            strategy_returns = preds * returns_cv_val\n",
    "            sharpe = calculate_sharpe_with_costs(strategy_returns, CONFIG['transaction_cost'])\n",
    "            sharpe_scores.append(sharpe if not np.isnan(sharpe) else 0)\n",
    "        except Exception as e:\n",
    "            print(f\"Trial failed: {e}\")\n",
    "            return -10  # Penalty for failed trials\n",
    "    \n",
    "    return np.mean(sharpe_scores) if sharpe_scores else -10\n",
    "\n",
    "print(\"\\n--- Starting Optuna Optimization ---\")\n",
    "\n",
    "# Run Optuna study\n",
    "study = optuna.create_study(direction='maximize', \n",
    "                          sampler=optuna.samplers.TPESampler(seed=CONFIG['random_state']))\n",
    "study.optimize(enhanced_objective, n_trials=CONFIG['n_trials'], show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n--- Optimization Results ---\")\n",
    "print(f\"Best Sharpe ratio: {study.best_value:.4f}\")\n",
    "print(f\"Best parameters: {study.best_params}\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "# Extract pipeline parameters\n",
    "pca_components = best_params.pop('pca_n_components')\n",
    "selector_threshold = best_params.pop('selector_threshold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be48f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. TRAIN FINAL MODEL ---\n",
    "print(\"\\n--- Training Final Model ---\")\n",
    "\n",
    "final_model = XGBClassifier(**best_params,\n",
    "                          scale_pos_weight=neg_to_pos_ratio,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=CONFIG['random_state'],\n",
    "                          n_jobs=-1,\n",
    "                          tree_method='hist')\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_select', SelectFromModel(final_model, threshold=selector_threshold)),\n",
    "    ('pca', PCA(n_components=pca_components)),\n",
    "    ('model', final_model)\n",
    "])\n",
    "\n",
    "# Fit on training data with validation for early stopping\n",
    "fit_params = {\n",
    "    \"model__early_stopping_rounds\": 20,\n",
    "    \"model__eval_set\": [(X_val_stable, y_val)],\n",
    "    \"model__verbose\": True\n",
    "}\n",
    "\n",
    "final_pipeline.fit(X_train_stable, y_train, **fit_params)\n",
    "print(\"✅ Final model trained with early stopping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. COMPREHENSIVE MODEL EVALUATION ---\n",
    "def evaluate_model_comprehensive(pipeline, X_test, y_test, returns_test, regimes_test, set_name=\"Test\"):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    print(f\"\\n--- {set_name} Set Evaluation ---\")\n",
    "    \n",
    "    # Basic predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Strategy returns\n",
    "    strategy_returns = y_pred * returns_test\n",
    "    \n",
    "    # Performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    sharpe = calculate_sharpe_with_costs(strategy_returns, CONFIG['transaction_cost'])\n",
    "    max_dd = calculate_max_drawdown(strategy_returns.cumsum())\n",
    "    total_return = strategy_returns.sum()\n",
    "    \n",
    "    # Win rate and trade statistics\n",
    "    winning_trades = strategy_returns[strategy_returns > 0]\n",
    "    losing_trades = strategy_returns[strategy_returns < 0]\n",
    "    win_rate = len(winning_trades) / len(strategy_returns[strategy_returns != 0]) if len(strategy_returns[strategy_returns != 0]) > 0 else 0\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Sharpe Ratio (w/ costs): {sharpe:.4f}\")\n",
    "    print(f\"Total Return: {total_return:.4f}\")\n",
    "    print(f\"Max Drawdown: {max_dd:.4f}\")\n",
    "    print(f\"Win Rate: {win_rate:.4f}\")\n",
    "    print(f\"Avg Winning Trade: {winning_trades.mean():.6f}\")\n",
    "    print(f\"Avg Losing Trade: {losing_trades.mean():.6f}\")\n",
    "    print(f\"Number of Trades: {(y_pred != 0).sum()}\")\n",
    "    \n",
    "    # Regime-specific performance\n",
    "    if regimes_test is not None:\n",
    "        print(f\"\\nRegime Performance:\")\n",
    "        for regime in regimes_test.unique():\n",
    "            regime_mask = regimes_test == regime\n",
    "            if regime_mask.sum() > 10:\n",
    "                regime_returns = strategy_returns[regime_mask]\n",
    "                regime_sharpe = calculate_sharpe_with_costs(regime_returns, CONFIG['transaction_cost'])\n",
    "                regime_names = {0: 'Low Vol', 1: 'Normal Vol', 2: 'High Vol'}\n",
    "                print(f\"  {regime_names.get(regime, f'Regime {regime}')}: Sharpe = {regime_sharpe:.3f} ({regime_mask.sum()} samples)\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'sharpe': sharpe,\n",
    "        'total_return': total_return,\n",
    "        'max_drawdown': max_dd,\n",
    "        'win_rate': win_rate,\n",
    "        'n_trades': (y_pred != 0).sum()\n",
    "    }\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_regimes = regimes[val_mask] if len(regimes[val_mask]) > 0 else None\n",
    "val_results = evaluate_model_comprehensive(final_pipeline, X_val_stable, y_val, \n",
    "                                         returns_val, val_regimes, \"Validation\")\n",
    "\n",
    "# Evaluate on test set (final, unbiased evaluation)\n",
    "test_regimes = regimes[test_mask] if len(regimes[test_mask]) > 0 else None\n",
    "test_results = evaluate_model_comprehensive(final_pipeline, X_test_stable, y_test, \n",
    "                                          returns_test, test_regimes, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a2a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. ROBUST PERMUTATION IMPORTANCE ---\n",
    "print(\"\\n--- Permutation Importance Analysis ---\")\n",
    "\n",
    "# Use only training data for feature importance to avoid bias\n",
    "pi_result = permutation_importance(final_pipeline, X_train_stable, y_train, \n",
    "                                 n_repeats=10, random_state=CONFIG['random_state'], n_jobs=-1)\n",
    "\n",
    "# Get selected features after pipeline fitting\n",
    "selected_features = X_train_stable.columns[final_pipeline.named_steps['feature_select'].get_support()]\n",
    "sorted_idx = pi_result.importances_mean.argsort()[::-1]\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "for i in sorted_idx[:10]:\n",
    "    feature_name = selected_features[i]\n",
    "    importance_mean = pi_result.importances_mean[i]\n",
    "    importance_std = pi_result.importances_std[i]\n",
    "    print(f\"  {feature_name}: {importance_mean:.4f} ± {importance_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56336c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. OVERFITTING CHECKS ---\n",
    "print(\"\\n--- Overfitting Analysis ---\")\n",
    "\n",
    "# Compare train vs validation performance\n",
    "train_pred = final_pipeline.predict(X_train_stable)\n",
    "train_strategy_returns = train_pred * returns_train\n",
    "train_sharpe = calculate_sharpe_with_costs(train_strategy_returns, CONFIG['transaction_cost'])\n",
    "\n",
    "print(f\"Training Sharpe: {train_sharpe:.4f}\")\n",
    "print(f\"Validation Sharpe: {val_results['sharpe']:.4f}\")\n",
    "print(f\"Test Sharpe: {test_results['sharpe']:.4f}\")\n",
    "\n",
    "sharpe_degradation = (train_sharpe - test_results['sharpe']) / abs(train_sharpe) if train_sharpe != 0 else 0\n",
    "print(f\"Sharpe degradation (train→test): {sharpe_degradation:.2%}\")\n",
    "\n",
    "if sharpe_degradation > 0.5:\n",
    "    print(\"⚠️  Warning: Significant performance degradation detected. Model may be overfitting.\")\n",
    "elif sharpe_degradation > 0.2:\n",
    "    print(\"⚠️  Caution: Moderate performance degradation. Monitor in backtesting.\")\n",
    "else:\n",
    "    print(\"✅ Performance degradation within acceptable limits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e773095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. MODEL PERSISTENCE ---\n",
    "os.makedirs(CONFIG['model_dir'], exist_ok=True)\n",
    "\n",
    "# Save the final pipeline\n",
    "model_filename = os.path.join(CONFIG['model_dir'], \"final_xgb_optuna_pipeline_enhanced.pkl\")\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(final_pipeline, f)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'config': CONFIG,\n",
    "    'best_params': {**best_params, 'pca_n_components': pca_components, 'selector_threshold': selector_threshold},\n",
    "    'class_imbalance_ratio': neg_to_pos_ratio,\n",
    "    'selected_features': list(selected_features),\n",
    "    'stable_features': stable_features,\n",
    "    'validation_results': val_results,\n",
    "    'test_results': test_results,\n",
    "    'train_sharpe': train_sharpe,\n",
    "    'feature_importance': {\n",
    "        feature: float(importance) \n",
    "        for feature, importance in zip(selected_features[sorted_idx[:20]], \n",
    "                                     pi_result.importances_mean[sorted_idx[:20]])\n",
    "    },\n",
    "    'training_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "metadata_filename = os.path.join(CONFIG['model_dir'], \"model_metadata_enhanced.json\")\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✅ Enhanced pipeline saved as '{model_filename}'\")\n",
    "print(f\"✅ Model metadata saved as '{metadata_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. REGIME-AWARE FINAL VALIDATION ---\n",
    "if len(regimes) > 0:\n",
    "    print(\"\\n--- Final Regime Analysis ---\")\n",
    "    regime_performance = regime_aware_validation(X_test_stable, y_test, returns_test, test_regimes, final_pipeline, CONFIG['transaction_cost'])\n",
    "\n",
    "print(\"\\n--- Summary ---\")\n",
    "print(f\"Final Test Sharpe Ratio: {test_results['sharpe']:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_results['accuracy']:.4f}\")\n",
    "print(f\"Model ready for backtesting phase.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

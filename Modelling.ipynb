{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_features import prepare_data_for_ml, create_target_variable\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59a5d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Data Preparation Pipeline ---\n",
      "Fetching data for 6 tickers from 1986-01-01 to 2023-01-01...\n",
      "\n",
      "Discovered stock prefixes: ['COST', 'KO', 'PEP', 'PG', 'WMT', '^GSPC']\n",
      "\n",
      "Processing features for stock prefix: COST\n",
      "  - Calculating ATR for COST (window=14)...\n",
      "  - Calculating RSI for COST (window=14)...\n",
      "  - Calculating MACD for COST (fast=12, slow=26, signal=9)...\n",
      "\n",
      "Processing features for stock prefix: KO\n",
      "  - Calculating ATR for KO (window=14)...\n",
      "  - Calculating RSI for KO (window=14)...\n",
      "  - Calculating MACD for KO (fast=12, slow=26, signal=9)...\n",
      "\n",
      "Processing features for stock prefix: PEP\n",
      "  - Calculating ATR for PEP (window=14)...\n",
      "  - Calculating RSI for PEP (window=14)...\n",
      "  - Calculating MACD for PEP (fast=12, slow=26, signal=9)...\n",
      "\n",
      "Processing features for stock prefix: PG\n",
      "  - Calculating ATR for PG (window=14)...\n",
      "  - Calculating RSI for PG (window=14)...\n",
      "  - Calculating MACD for PG (fast=12, slow=26, signal=9)...\n",
      "\n",
      "Processing features for stock prefix: WMT\n",
      "  - Calculating ATR for WMT (window=14)...\n",
      "  - Calculating RSI for WMT (window=14)...\n",
      "  - Calculating MACD for WMT (fast=12, slow=26, signal=9)...\n",
      "\n",
      "Processing features for stock prefix: ^GSPC\n",
      "  - Calculating ATR for ^GSPC (window=14)...\n",
      "  - Calculating RSI for ^GSPC (window=14)...\n",
      "  - Calculating MACD for ^GSPC (fast=12, slow=26, signal=9)...\n",
      "\n",
      "Applying general features and targets...\n",
      "  - Adding lagged features...\n",
      "\n",
      "Dropped 49 rows due to NaN values after feature engineering.\n",
      "\n",
      "--- Data Preparation Complete ---\n",
      "Final engineered data saved to consumer_stocks_final_engineered.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for your data pipeline\n",
    "tickers_list = ['PG', 'KO', 'PEP', 'WMT', 'COST', '^GSPC']\n",
    "start_date_str = '1986-01-01'\n",
    "end_date_str = '2023-01-01'\n",
    "output_filename = \"consumer_stocks_final_engineered.csv\"\n",
    "\n",
    "# Make the single function call to run the entire pipeline\n",
    "final_engineered_df = prepare_data_for_ml(\n",
    "    tickers=tickers_list,\n",
    "    start_date=start_date_str,\n",
    "    end_date=end_date_str,\n",
    "    output_engineered_csv=output_filename\n",
    ")\n",
    "\n",
    "# 2. Create your target variable before modeling\n",
    "'''\n",
    "    ticker (str): The stock ticker for the target.\n",
    "    window (int): The number of days for the return period (e.g., 1 for next day, 5 for a week).\n",
    "    threshold (float): The minimum return to be considered \"up\".\n",
    "'''\n",
    "target_ticker = 'WMT'\n",
    "\n",
    "data_target = create_target_variable(final_engineered_df.copy(), target_ticker, window=5, threshold=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "800c3600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values per column:\n",
      "Close_COST                    0\n",
      "Close_KO                      0\n",
      "Close_PEP                     0\n",
      "Close_PG                      0\n",
      "Close_WMT                     0\n",
      "                             ..\n",
      "^GSPC_RSI14_lag3              0\n",
      "^GSPC_RSI14_lag5              0\n",
      "^GSPC_Volume_MA_Ratio_lag1    0\n",
      "^GSPC_Volume_MA_Ratio_lag3    0\n",
      "^GSPC_Volume_MA_Ratio_lag5    0\n",
      "Length: 290, dtype: int64\n",
      "\n",
      "Total number of NaN values in the DataFrame: 0\n"
     ]
    }
   ],
   "source": [
    "# 3. HANDLE MISSING DATA\n",
    "nan_per_column = df.isnull().sum()\n",
    "print(\"Number of NaN values per column:\")\n",
    "print(nan_per_column)\n",
    "\n",
    "# Count total NaN values in the entire DataFrame\n",
    "total_nan = df.isnull().sum().sum()\n",
    "print(\"\\nTotal number of NaN values in the DataFrame:\", total_nan)\n",
    "\n",
    "#df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be48f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (8644, 286), (8644,)\n",
      "Testing data shape: (503, 286), (503,)\n"
     ]
    }
   ],
   "source": [
    "# 4. SEPARATE FEATURES (X) AND TARGET (y)\n",
    "# The data is ready to be used with the best performing target\n",
    "target_ticker = 'WMT'\n",
    "data_target = create_target_variable(final_engineered_df.copy(), target_ticker, window=5, threshold=0.01)\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "target_col_name = f'{target_ticker}_Target'\n",
    "target_return_col_name = [col for col in data_target.columns if col.startswith(f'{target_ticker}_target_return_')][0]\n",
    "columns_to_drop = [target_col_name, target_return_col_name, f'Open_{target_ticker}', f'High_{target_ticker}', f'Low_{target_ticker}', f'Close_{target_ticker}']\n",
    "X = data_target.drop(columns=columns_to_drop)\n",
    "y = data_target[target_col_name]\n",
    "\n",
    "X_train = X.loc[:'2021-01-01'].copy()\n",
    "y_train = y.loc[:'2021-01-01'].copy()\n",
    "X_test = X.loc['2021-01-01':].copy()\n",
    "y_test = y.loc['2021-01-01':].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b69295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Evaluation on Test Data ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       317\n",
      "           1       0.44      0.44      0.44       186\n",
      "\n",
      "    accuracy                           0.58       503\n",
      "   macro avg       0.55      0.55      0.55       503\n",
      "weighted avg       0.58      0.58      0.58       503\n",
      "\n",
      "\n",
      "--- Top 10 Feature Importances ---\n",
      "COST_MACD_Signal          0.006768\n",
      "^GSPC_MACD_Line           0.006529\n",
      "WMT_BB_Bandwidth20        0.006481\n",
      "WMT_vs_^GSPC_ATR_Ratio    0.006298\n",
      "PG_MACD_Signal            0.005963\n",
      "WMT_vs_PEP_CloseRatio     0.005767\n",
      "WMT_ADX_14                0.005538\n",
      "WMT_RSI14                 0.005367\n",
      "^GSPC_PlusDI_14           0.005356\n",
      "PEP_ADX_14                0.005336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"--- Model Evaluation on Test Data ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Feature Importances\n",
    "print(\"\\n--- Top 10 Feature Importances ---\")\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "print(feature_importances.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf3328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV fitting. This may take some time...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "Best parameters found:  {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.9}\n",
      "Best cross-validation accuracy: 0.47\n",
      "\n",
      "--- Tuned XGBoost Model Evaluation on Test Data ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69       317\n",
      "           1       0.41      0.31      0.35       186\n",
      "\n",
      "    accuracy                           0.58       503\n",
      "   macro avg       0.53      0.52      0.52       503\n",
      "weighted avg       0.56      0.58      0.56       503\n",
      "\n",
      "\n",
      "--- Top 10 Feature Importances (Tuned XGBoost) ---\n",
      "Close_WMT_lag1            0.018809\n",
      "^GSPC_OpenClose_Range     0.014019\n",
      "WMT_BB_Lower20            0.012717\n",
      "^GSPC_Stoch_K_14          0.011662\n",
      "^GSPC_Stoch_D_14_3        0.011606\n",
      "^GSPC_RSI14               0.010915\n",
      "PG_ATR14                  0.010513\n",
      "^GSPC_BB_PctB20           0.010307\n",
      "COST_ATR14                0.010078\n",
      "WMT_vs_^GSPC_ATR_Ratio    0.010011\n"
     ]
    }
   ],
   "source": [
    "# Define the base model using the best parameters\n",
    "base_xgboost = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=neg_to_pos_ratio,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Fit the base model to the entire training set\n",
    "base_xgboost.fit(X_train, y_train)\n",
    "\n",
    "# Use SelectFromModel to select features with an importance above the median\n",
    "selector = SelectFromModel(base_xgboost, prefit=True, threshold='median')\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "print(f\"Original number of features: {X_train.shape[1]}\")\n",
    "print(f\"Number of features after selection: {X_train_selected.shape[1]}\")\n",
    "\n",
    "print(\"\\n--- 2. Training the final model on the selected features ---\")\n",
    "\n",
    "# Define the final model with the best parameters and the class imbalance handled\n",
    "final_xgboost_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=neg_to_pos_ratio,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Fit the final model to the reduced feature set\n",
    "final_xgboost_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the final model on the test data\n",
    "y_pred_final = final_xgboost_model.predict(X_test_selected)\n",
    "print(\"\\n--- Final Model Evaluation on Test Data with Pruned Features ---\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "\n",
    "# Optional: Identify the names of the selected features and their importances\n",
    "selected_features_mask = selector.get_support()\n",
    "selected_feature_names = X_train.columns[selected_features_mask]\n",
    "\n",
    "print(\"\\n--- Top 10 Feature Importances (Final Model) ---\")\n",
    "final_feature_importances = pd.Series(final_xgboost_model.feature_importances_, index=selected_feature_names).sort_values(ascending=False)\n",
    "print(final_feature_importances.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3609f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
